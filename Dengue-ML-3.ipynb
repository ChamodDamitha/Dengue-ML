{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns # data visualization library  \n",
    "import numpy as np\n",
    "np.random.seed(1337)  # for reproducibility\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "\n",
    "pd.set_option('display.max_columns', 50)\n",
    "\n",
    "seed = 7\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_feature_filename = \"dengue_features_train.csv\"\n",
    "train_label_filename = \"dengue_labels_train.csv\"\n",
    "\n",
    "test_feature_filename = \"dengue_features_test.csv\"\n",
    "\n",
    "train_features = pd.read_csv(train_feature_filename, index_col=[0,2])\n",
    "\n",
    "train_labels = pd.read_csv(train_label_filename, index_col=[0,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>week_start_date</th>\n",
       "      <th>ndvi_ne</th>\n",
       "      <th>ndvi_nw</th>\n",
       "      <th>ndvi_se</th>\n",
       "      <th>ndvi_sw</th>\n",
       "      <th>precipitation_amt_mm</th>\n",
       "      <th>reanalysis_air_temp_k</th>\n",
       "      <th>reanalysis_avg_temp_k</th>\n",
       "      <th>reanalysis_dew_point_temp_k</th>\n",
       "      <th>reanalysis_max_air_temp_k</th>\n",
       "      <th>reanalysis_min_air_temp_k</th>\n",
       "      <th>reanalysis_precip_amt_kg_per_m2</th>\n",
       "      <th>reanalysis_relative_humidity_percent</th>\n",
       "      <th>reanalysis_sat_precip_amt_mm</th>\n",
       "      <th>reanalysis_specific_humidity_g_per_kg</th>\n",
       "      <th>reanalysis_tdtr_k</th>\n",
       "      <th>station_avg_temp_c</th>\n",
       "      <th>station_diur_temp_rng_c</th>\n",
       "      <th>station_max_temp_c</th>\n",
       "      <th>station_min_temp_c</th>\n",
       "      <th>station_precip_mm</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>city</th>\n",
       "      <th>weekofyear</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">sj</th>\n",
       "      <th>18</th>\n",
       "      <td>1990</td>\n",
       "      <td>641433600</td>\n",
       "      <td>0.122600</td>\n",
       "      <td>0.103725</td>\n",
       "      <td>0.198483</td>\n",
       "      <td>0.177617</td>\n",
       "      <td>12.42</td>\n",
       "      <td>297.572857</td>\n",
       "      <td>297.742857</td>\n",
       "      <td>292.414286</td>\n",
       "      <td>299.8</td>\n",
       "      <td>295.9</td>\n",
       "      <td>32.00</td>\n",
       "      <td>73.365714</td>\n",
       "      <td>12.42</td>\n",
       "      <td>14.012857</td>\n",
       "      <td>2.628571</td>\n",
       "      <td>25.442857</td>\n",
       "      <td>6.900000</td>\n",
       "      <td>29.4</td>\n",
       "      <td>20.0</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1990</td>\n",
       "      <td>642038400</td>\n",
       "      <td>0.169900</td>\n",
       "      <td>0.142175</td>\n",
       "      <td>0.162357</td>\n",
       "      <td>0.155486</td>\n",
       "      <td>22.82</td>\n",
       "      <td>298.211429</td>\n",
       "      <td>298.442857</td>\n",
       "      <td>293.951429</td>\n",
       "      <td>300.9</td>\n",
       "      <td>296.4</td>\n",
       "      <td>17.94</td>\n",
       "      <td>77.368571</td>\n",
       "      <td>22.82</td>\n",
       "      <td>15.372857</td>\n",
       "      <td>2.371429</td>\n",
       "      <td>26.714286</td>\n",
       "      <td>6.371429</td>\n",
       "      <td>31.7</td>\n",
       "      <td>22.2</td>\n",
       "      <td>8.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1990</td>\n",
       "      <td>642643200</td>\n",
       "      <td>0.032250</td>\n",
       "      <td>0.172967</td>\n",
       "      <td>0.157200</td>\n",
       "      <td>0.170843</td>\n",
       "      <td>34.54</td>\n",
       "      <td>298.781429</td>\n",
       "      <td>298.878571</td>\n",
       "      <td>295.434286</td>\n",
       "      <td>300.5</td>\n",
       "      <td>297.3</td>\n",
       "      <td>26.10</td>\n",
       "      <td>82.052857</td>\n",
       "      <td>34.54</td>\n",
       "      <td>16.848571</td>\n",
       "      <td>2.300000</td>\n",
       "      <td>26.714286</td>\n",
       "      <td>6.485714</td>\n",
       "      <td>32.2</td>\n",
       "      <td>22.8</td>\n",
       "      <td>41.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1990</td>\n",
       "      <td>643248000</td>\n",
       "      <td>0.128633</td>\n",
       "      <td>0.245067</td>\n",
       "      <td>0.227557</td>\n",
       "      <td>0.235886</td>\n",
       "      <td>15.36</td>\n",
       "      <td>298.987143</td>\n",
       "      <td>299.228571</td>\n",
       "      <td>295.310000</td>\n",
       "      <td>301.4</td>\n",
       "      <td>297.0</td>\n",
       "      <td>13.90</td>\n",
       "      <td>80.337143</td>\n",
       "      <td>15.36</td>\n",
       "      <td>16.672857</td>\n",
       "      <td>2.428571</td>\n",
       "      <td>27.471429</td>\n",
       "      <td>6.771429</td>\n",
       "      <td>33.3</td>\n",
       "      <td>23.3</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1990</td>\n",
       "      <td>643852800</td>\n",
       "      <td>0.196200</td>\n",
       "      <td>0.262200</td>\n",
       "      <td>0.251200</td>\n",
       "      <td>0.247340</td>\n",
       "      <td>7.52</td>\n",
       "      <td>299.518571</td>\n",
       "      <td>299.664286</td>\n",
       "      <td>295.821429</td>\n",
       "      <td>301.9</td>\n",
       "      <td>297.5</td>\n",
       "      <td>12.20</td>\n",
       "      <td>80.460000</td>\n",
       "      <td>7.52</td>\n",
       "      <td>17.210000</td>\n",
       "      <td>3.014286</td>\n",
       "      <td>28.942857</td>\n",
       "      <td>9.371429</td>\n",
       "      <td>35.0</td>\n",
       "      <td>23.9</td>\n",
       "      <td>5.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 year  week_start_date   ndvi_ne   ndvi_nw   ndvi_se  \\\n",
       "city weekofyear                                                        \n",
       "sj   18          1990        641433600  0.122600  0.103725  0.198483   \n",
       "     19          1990        642038400  0.169900  0.142175  0.162357   \n",
       "     20          1990        642643200  0.032250  0.172967  0.157200   \n",
       "     21          1990        643248000  0.128633  0.245067  0.227557   \n",
       "     22          1990        643852800  0.196200  0.262200  0.251200   \n",
       "\n",
       "                  ndvi_sw  precipitation_amt_mm  reanalysis_air_temp_k  \\\n",
       "city weekofyear                                                          \n",
       "sj   18          0.177617                 12.42             297.572857   \n",
       "     19          0.155486                 22.82             298.211429   \n",
       "     20          0.170843                 34.54             298.781429   \n",
       "     21          0.235886                 15.36             298.987143   \n",
       "     22          0.247340                  7.52             299.518571   \n",
       "\n",
       "                 reanalysis_avg_temp_k  reanalysis_dew_point_temp_k  \\\n",
       "city weekofyear                                                       \n",
       "sj   18                     297.742857                   292.414286   \n",
       "     19                     298.442857                   293.951429   \n",
       "     20                     298.878571                   295.434286   \n",
       "     21                     299.228571                   295.310000   \n",
       "     22                     299.664286                   295.821429   \n",
       "\n",
       "                 reanalysis_max_air_temp_k  reanalysis_min_air_temp_k  \\\n",
       "city weekofyear                                                         \n",
       "sj   18                              299.8                      295.9   \n",
       "     19                              300.9                      296.4   \n",
       "     20                              300.5                      297.3   \n",
       "     21                              301.4                      297.0   \n",
       "     22                              301.9                      297.5   \n",
       "\n",
       "                 reanalysis_precip_amt_kg_per_m2  \\\n",
       "city weekofyear                                    \n",
       "sj   18                                    32.00   \n",
       "     19                                    17.94   \n",
       "     20                                    26.10   \n",
       "     21                                    13.90   \n",
       "     22                                    12.20   \n",
       "\n",
       "                 reanalysis_relative_humidity_percent  \\\n",
       "city weekofyear                                         \n",
       "sj   18                                     73.365714   \n",
       "     19                                     77.368571   \n",
       "     20                                     82.052857   \n",
       "     21                                     80.337143   \n",
       "     22                                     80.460000   \n",
       "\n",
       "                 reanalysis_sat_precip_amt_mm  \\\n",
       "city weekofyear                                 \n",
       "sj   18                                 12.42   \n",
       "     19                                 22.82   \n",
       "     20                                 34.54   \n",
       "     21                                 15.36   \n",
       "     22                                  7.52   \n",
       "\n",
       "                 reanalysis_specific_humidity_g_per_kg  reanalysis_tdtr_k  \\\n",
       "city weekofyear                                                             \n",
       "sj   18                                      14.012857           2.628571   \n",
       "     19                                      15.372857           2.371429   \n",
       "     20                                      16.848571           2.300000   \n",
       "     21                                      16.672857           2.428571   \n",
       "     22                                      17.210000           3.014286   \n",
       "\n",
       "                 station_avg_temp_c  station_diur_temp_rng_c  \\\n",
       "city weekofyear                                                \n",
       "sj   18                   25.442857                 6.900000   \n",
       "     19                   26.714286                 6.371429   \n",
       "     20                   26.714286                 6.485714   \n",
       "     21                   27.471429                 6.771429   \n",
       "     22                   28.942857                 9.371429   \n",
       "\n",
       "                 station_max_temp_c  station_min_temp_c  station_precip_mm  \n",
       "city weekofyear                                                             \n",
       "sj   18                        29.4                20.0               16.0  \n",
       "     19                        31.7                22.2                8.6  \n",
       "     20                        32.2                22.8               41.4  \n",
       "     21                        33.3                23.3                4.0  \n",
       "     22                        35.0                23.9                5.8  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_features.fillna(method='ffill', inplace=True)\n",
    "train_features['week_start_date'] = pd.to_datetime(train_features['week_start_date']).astype(np.int64) // 10**9\n",
    "\n",
    "train_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.694458</td>\n",
       "      <td>-1.730015</td>\n",
       "      <td>0.618730</td>\n",
       "      <td>0.406732</td>\n",
       "      <td>0.386803</td>\n",
       "      <td>0.207545</td>\n",
       "      <td>-0.513013</td>\n",
       "      <td>-1.282015</td>\n",
       "      <td>-1.253898</td>\n",
       "      <td>-1.714497</td>\n",
       "      <td>-1.265623</td>\n",
       "      <td>-1.079864</td>\n",
       "      <td>0.045021</td>\n",
       "      <td>-1.538475</td>\n",
       "      <td>-0.513013</td>\n",
       "      <td>-1.624972</td>\n",
       "      <td>0.228762</td>\n",
       "      <td>-1.100409</td>\n",
       "      <td>0.173508</td>\n",
       "      <td>-1.278687</td>\n",
       "      <td>-1.723054</td>\n",
       "      <td>-0.367775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.694458</td>\n",
       "      <td>-1.726327</td>\n",
       "      <td>1.069847</td>\n",
       "      <td>0.827328</td>\n",
       "      <td>-0.240873</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>-0.279993</td>\n",
       "      <td>-0.765638</td>\n",
       "      <td>-0.679726</td>\n",
       "      <td>-0.734948</td>\n",
       "      <td>-0.391773</td>\n",
       "      <td>-0.693609</td>\n",
       "      <td>-0.350886</td>\n",
       "      <td>-0.355236</td>\n",
       "      <td>-0.279993</td>\n",
       "      <td>-0.753081</td>\n",
       "      <td>-0.287676</td>\n",
       "      <td>-0.201443</td>\n",
       "      <td>-0.459811</td>\n",
       "      <td>0.059942</td>\n",
       "      <td>-0.261722</td>\n",
       "      <td>-0.620780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.694458</td>\n",
       "      <td>-1.722639</td>\n",
       "      <td>-0.242970</td>\n",
       "      <td>1.164151</td>\n",
       "      <td>-0.330476</td>\n",
       "      <td>0.086137</td>\n",
       "      <td>-0.017398</td>\n",
       "      <td>-0.304710</td>\n",
       "      <td>-0.322333</td>\n",
       "      <td>0.210006</td>\n",
       "      <td>-0.709537</td>\n",
       "      <td>0.001651</td>\n",
       "      <td>-0.121114</td>\n",
       "      <td>1.029432</td>\n",
       "      <td>-0.017398</td>\n",
       "      <td>0.192993</td>\n",
       "      <td>-0.431131</td>\n",
       "      <td>-0.201443</td>\n",
       "      <td>-0.322877</td>\n",
       "      <td>0.350949</td>\n",
       "      <td>0.136822</td>\n",
       "      <td>0.500648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.694458</td>\n",
       "      <td>-1.718951</td>\n",
       "      <td>0.676272</td>\n",
       "      <td>1.952837</td>\n",
       "      <td>0.891947</td>\n",
       "      <td>1.251919</td>\n",
       "      <td>-0.447140</td>\n",
       "      <td>-0.138360</td>\n",
       "      <td>-0.035247</td>\n",
       "      <td>0.130805</td>\n",
       "      <td>0.005432</td>\n",
       "      <td>-0.230103</td>\n",
       "      <td>-0.464646</td>\n",
       "      <td>0.522269</td>\n",
       "      <td>-0.447140</td>\n",
       "      <td>0.080343</td>\n",
       "      <td>-0.172912</td>\n",
       "      <td>0.333897</td>\n",
       "      <td>0.019457</td>\n",
       "      <td>0.991163</td>\n",
       "      <td>0.468943</td>\n",
       "      <td>-0.778054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.694458</td>\n",
       "      <td>-1.715262</td>\n",
       "      <td>1.320680</td>\n",
       "      <td>2.140254</td>\n",
       "      <td>1.302732</td>\n",
       "      <td>1.457218</td>\n",
       "      <td>-0.622801</td>\n",
       "      <td>0.291378</td>\n",
       "      <td>0.322146</td>\n",
       "      <td>0.456714</td>\n",
       "      <td>0.402637</td>\n",
       "      <td>0.156153</td>\n",
       "      <td>-0.512515</td>\n",
       "      <td>0.558586</td>\n",
       "      <td>-0.622801</td>\n",
       "      <td>0.424704</td>\n",
       "      <td>1.003419</td>\n",
       "      <td>1.374273</td>\n",
       "      <td>3.134700</td>\n",
       "      <td>1.980584</td>\n",
       "      <td>0.867488</td>\n",
       "      <td>-0.716512</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         0         1         2         3         4         5         6   \\\n",
       "0 -1.694458 -1.730015  0.618730  0.406732  0.386803  0.207545 -0.513013   \n",
       "1 -1.694458 -1.726327  1.069847  0.827328 -0.240873 -0.189115 -0.279993   \n",
       "2 -1.694458 -1.722639 -0.242970  1.164151 -0.330476  0.086137 -0.017398   \n",
       "3 -1.694458 -1.718951  0.676272  1.952837  0.891947  1.251919 -0.447140   \n",
       "4 -1.694458 -1.715262  1.320680  2.140254  1.302732  1.457218 -0.622801   \n",
       "\n",
       "         7         8         9         10        11        12        13  \\\n",
       "0 -1.282015 -1.253898 -1.714497 -1.265623 -1.079864  0.045021 -1.538475   \n",
       "1 -0.765638 -0.679726 -0.734948 -0.391773 -0.693609 -0.350886 -0.355236   \n",
       "2 -0.304710 -0.322333  0.210006 -0.709537  0.001651 -0.121114  1.029432   \n",
       "3 -0.138360 -0.035247  0.130805  0.005432 -0.230103 -0.464646  0.522269   \n",
       "4  0.291378  0.322146  0.456714  0.402637  0.156153 -0.512515  0.558586   \n",
       "\n",
       "         14        15        16        17        18        19        20  \\\n",
       "0 -0.513013 -1.624972  0.228762 -1.100409  0.173508 -1.278687 -1.723054   \n",
       "1 -0.279993 -0.753081 -0.287676 -0.201443 -0.459811  0.059942 -0.261722   \n",
       "2 -0.017398  0.192993 -0.431131 -0.201443 -0.322877  0.350949  0.136822   \n",
       "3 -0.447140  0.080343 -0.172912  0.333897  0.019457  0.991163  0.468943   \n",
       "4 -0.622801  0.424704  1.003419  1.374273  3.134700  1.980584  0.867488   \n",
       "\n",
       "         21  \n",
       "0 -0.367775  \n",
       "1 -0.620780  \n",
       "2  0.500648  \n",
       "3 -0.778054  \n",
       "4 -0.716512  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Standardizing the data\n",
    "scaler = StandardScaler()\n",
    "    \n",
    "\n",
    "# Seperate data for San Juan\n",
    "sj_train_features = pd.DataFrame(scaler.fit_transform(train_features.loc['sj']))\n",
    "sj_train_labels = train_labels.loc['sj']\n",
    "\n",
    "# Separate data for Iquitos\n",
    "iq_train_features = pd.DataFrame(scaler.fit_transform(train_features.loc['iq']))\n",
    "iq_train_labels = train_labels.loc['iq']\n",
    "\n",
    "sj_train_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(data_path, labels_path=None):\n",
    "    # select features we want\n",
    "    features = ['reanalysis_specific_humidity_g_per_kg', \n",
    "                 'reanalysis_dew_point_temp_k', \n",
    "                 'station_avg_temp_c', \n",
    "                 'station_min_temp_c', 'week_start_date', 'precipitation_amt_mm']\n",
    "\n",
    "    # load data and set index to city, year, weekofyear\n",
    "    df = pd.read_csv(data_path, index_col=[0, 2]) \n",
    "\n",
    "    df = df[features]\n",
    "    \n",
    "    for obs in range(1, 5):\n",
    "#         df[\"T1_\" + str(obs)] = df.reanalysis_dew_point_temp_k.shift(obs)\n",
    "        df[\"T2_\" + str(obs)] = df.precipitation_amt_mm.shift(obs)\n",
    "    for obs in range(1, 5):\n",
    "#         df[\"T1_\" + str(obs)].fillna(0.00, inplace=True)\n",
    "        df[\"T2_\" + str(obs)].fillna(0.00, inplace=True)\n",
    "    \n",
    "    df['week_start_date'] = pd.to_datetime(df['week_start_date'])\n",
    "    for i in xrange(1,5):\n",
    "        df['quarter_' + str(i)] = df['week_start_date'].apply(lambda date: 1 if (\n",
    "            ((i-1)*3<date.to_datetime().month) and (date.to_datetime().month <= i * 3)) else 0)\n",
    "        features.append('quarter_' + str(i))\n",
    "    \n",
    "    df = df.drop(['week_start_date', 'quarter_1', 'quarter_3'], axis=1)\n",
    "    features.remove('week_start_date')\n",
    "    \n",
    "    # fill missing values\n",
    "    df.fillna(method='ffill', inplace=True)\n",
    "\n",
    "    \n",
    "    # Standardizing the data\n",
    "    scaler = StandardScaler()\n",
    "    \n",
    "    sj_label = None\n",
    "    iq_label = None\n",
    "    # add labels to dataframe\n",
    "    if labels_path:\n",
    "        labels = pd.read_csv(labels_path, index_col=[0, 2])\n",
    "#         df = df.join(labels)\n",
    "        sj_label = pd.DataFrame(labels.loc['sj'])\n",
    "        iq_label = pd.DataFrame(labels.loc['iq'])\n",
    "\n",
    "    \n",
    "    # separate san juan and iquitos\n",
    "    sj = pd.DataFrame(scaler.fit_transform(df.loc['sj']))\n",
    "    iq = pd.DataFrame(scaler.fit_transform(df.loc['iq']))\n",
    "#     sj = pd.DataFrame(df.loc['sj'])\n",
    "#     iq = pd.DataFrame(df.loc['iq'])\n",
    "    \n",
    "    \n",
    "    return sj, iq, sj_label, iq_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/pandas/core/series.py:2551: FutureWarning: to_datetime is deprecated. Use self.to_pydatetime()\n",
      "  mapped = lib.map_infer(values, f, convert=convert_dtype)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.624972</td>\n",
       "      <td>-1.714497</td>\n",
       "      <td>-1.100409</td>\n",
       "      <td>-1.723054</td>\n",
       "      <td>-0.513013</td>\n",
       "      <td>-0.789396</td>\n",
       "      <td>-0.789396</td>\n",
       "      <td>-0.788797</td>\n",
       "      <td>-0.788651</td>\n",
       "      <td>1.732051</td>\n",
       "      <td>-0.570771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.753081</td>\n",
       "      <td>-0.734948</td>\n",
       "      <td>-0.201443</td>\n",
       "      <td>-0.261722</td>\n",
       "      <td>-0.279993</td>\n",
       "      <td>-0.510308</td>\n",
       "      <td>-0.789396</td>\n",
       "      <td>-0.788797</td>\n",
       "      <td>-0.788651</td>\n",
       "      <td>1.732051</td>\n",
       "      <td>-0.570771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.192993</td>\n",
       "      <td>0.210006</td>\n",
       "      <td>-0.201443</td>\n",
       "      <td>0.136822</td>\n",
       "      <td>-0.017398</td>\n",
       "      <td>-0.276611</td>\n",
       "      <td>-0.510308</td>\n",
       "      <td>-0.788797</td>\n",
       "      <td>-0.788651</td>\n",
       "      <td>1.732051</td>\n",
       "      <td>-0.570771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.080343</td>\n",
       "      <td>0.130805</td>\n",
       "      <td>0.333897</td>\n",
       "      <td>0.468943</td>\n",
       "      <td>-0.447140</td>\n",
       "      <td>-0.013252</td>\n",
       "      <td>-0.276611</td>\n",
       "      <td>-0.509777</td>\n",
       "      <td>-0.788651</td>\n",
       "      <td>1.732051</td>\n",
       "      <td>-0.570771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.424704</td>\n",
       "      <td>0.456714</td>\n",
       "      <td>1.374273</td>\n",
       "      <td>0.867488</td>\n",
       "      <td>-0.622801</td>\n",
       "      <td>-0.444244</td>\n",
       "      <td>-0.013252</td>\n",
       "      <td>-0.276136</td>\n",
       "      <td>-0.509650</td>\n",
       "      <td>1.732051</td>\n",
       "      <td>-0.570771</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         0         1         2         3         4         5         6   \\\n",
       "0 -1.624972 -1.714497 -1.100409 -1.723054 -0.513013 -0.789396 -0.789396   \n",
       "1 -0.753081 -0.734948 -0.201443 -0.261722 -0.279993 -0.510308 -0.789396   \n",
       "2  0.192993  0.210006 -0.201443  0.136822 -0.017398 -0.276611 -0.510308   \n",
       "3  0.080343  0.130805  0.333897  0.468943 -0.447140 -0.013252 -0.276611   \n",
       "4  0.424704  0.456714  1.374273  0.867488 -0.622801 -0.444244 -0.013252   \n",
       "\n",
       "         7         8         9         10  \n",
       "0 -0.788797 -0.788651  1.732051 -0.570771  \n",
       "1 -0.788797 -0.788651  1.732051 -0.570771  \n",
       "2 -0.788797 -0.788651  1.732051 -0.570771  \n",
       "3 -0.509777 -0.788651  1.732051 -0.570771  \n",
       "4 -0.276136 -0.509650  1.732051 -0.570771  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sj_train, iq_train, sj_label, iq_label = preprocess_data(train_feature_filename, labels_path=train_label_filename)\n",
    "\n",
    "sj_train.head()\n",
    "# sj_label.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.624972</td>\n",
       "      <td>-1.714497</td>\n",
       "      <td>-1.100409</td>\n",
       "      <td>-1.723054</td>\n",
       "      <td>-0.513013</td>\n",
       "      <td>-0.789396</td>\n",
       "      <td>-0.789396</td>\n",
       "      <td>-0.788797</td>\n",
       "      <td>-0.788651</td>\n",
       "      <td>1.732051</td>\n",
       "      <td>-0.570771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.753081</td>\n",
       "      <td>-0.734948</td>\n",
       "      <td>-0.201443</td>\n",
       "      <td>-0.261722</td>\n",
       "      <td>-0.279993</td>\n",
       "      <td>-0.510308</td>\n",
       "      <td>-0.789396</td>\n",
       "      <td>-0.788797</td>\n",
       "      <td>-0.788651</td>\n",
       "      <td>1.732051</td>\n",
       "      <td>-0.570771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.192993</td>\n",
       "      <td>0.210006</td>\n",
       "      <td>-0.201443</td>\n",
       "      <td>0.136822</td>\n",
       "      <td>-0.017398</td>\n",
       "      <td>-0.276611</td>\n",
       "      <td>-0.510308</td>\n",
       "      <td>-0.788797</td>\n",
       "      <td>-0.788651</td>\n",
       "      <td>1.732051</td>\n",
       "      <td>-0.570771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.080343</td>\n",
       "      <td>0.130805</td>\n",
       "      <td>0.333897</td>\n",
       "      <td>0.468943</td>\n",
       "      <td>-0.447140</td>\n",
       "      <td>-0.013252</td>\n",
       "      <td>-0.276611</td>\n",
       "      <td>-0.509777</td>\n",
       "      <td>-0.788651</td>\n",
       "      <td>1.732051</td>\n",
       "      <td>-0.570771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.424704</td>\n",
       "      <td>0.456714</td>\n",
       "      <td>1.374273</td>\n",
       "      <td>0.867488</td>\n",
       "      <td>-0.622801</td>\n",
       "      <td>-0.444244</td>\n",
       "      <td>-0.013252</td>\n",
       "      <td>-0.276136</td>\n",
       "      <td>-0.509650</td>\n",
       "      <td>1.732051</td>\n",
       "      <td>-0.570771</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         0         1         2         3         4         5         6   \\\n",
       "0 -1.624972 -1.714497 -1.100409 -1.723054 -0.513013 -0.789396 -0.789396   \n",
       "1 -0.753081 -0.734948 -0.201443 -0.261722 -0.279993 -0.510308 -0.789396   \n",
       "2  0.192993  0.210006 -0.201443  0.136822 -0.017398 -0.276611 -0.510308   \n",
       "3  0.080343  0.130805  0.333897  0.468943 -0.447140 -0.013252 -0.276611   \n",
       "4  0.424704  0.456714  1.374273  0.867488 -0.622801 -0.444244 -0.013252   \n",
       "\n",
       "         7         8         9         10  \n",
       "0 -0.788797 -0.788651  1.732051 -0.570771  \n",
       "1 -0.788797 -0.788651  1.732051 -0.570771  \n",
       "2 -0.788797 -0.788651  1.732051 -0.570771  \n",
       "3 -0.509777 -0.788651  1.732051 -0.570771  \n",
       "4 -0.276136 -0.509650  1.732051 -0.570771  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "sj_train_X, sj_test_X, sj_train_y, sj_test_y = train_test_split(sj_train, sj_label['total_cases'], test_size=0.25, random_state=0, shuffle=False)\n",
    "\n",
    "iq_train_X, iq_test_X, iq_train_y, iq_test_y = train_test_split(iq_train, iq_label['total_cases'], test_size=0.25, random_state=0, shuffle=False)\n",
    "\n",
    "sj_train_X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:15: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(units=1, activation=\"relu\", kernel_initializer=\"normal\")`\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 32)                384       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 8)                 136       \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 1,057\n",
      "Trainable params: 1,057\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 702 samples, validate on 234 samples\n",
      "Epoch 1/200\n",
      "702/702 [==============================] - 0s 673us/step - loss: 36.2436 - acc: 0.0128 - val_loss: 15.2798 - val_acc: 0.0598\n",
      "Epoch 2/200\n",
      "702/702 [==============================] - 0s 328us/step - loss: 25.3287 - acc: 0.0256 - val_loss: 16.3795 - val_acc: 0.0171\n",
      "Epoch 3/200\n",
      "702/702 [==============================] - 0s 292us/step - loss: 24.3970 - acc: 0.0256 - val_loss: 16.6016 - val_acc: 0.0085\n",
      "Epoch 4/200\n",
      "702/702 [==============================] - 0s 281us/step - loss: 24.2905 - acc: 0.0242 - val_loss: 17.9067 - val_acc: 0.0085\n",
      "Epoch 5/200\n",
      "702/702 [==============================] - 0s 265us/step - loss: 24.4096 - acc: 0.0285 - val_loss: 17.2655 - val_acc: 0.0256\n",
      "Epoch 6/200\n",
      "702/702 [==============================] - 0s 276us/step - loss: 24.3583 - acc: 0.0271 - val_loss: 16.8946 - val_acc: 0.0128\n",
      "Epoch 7/200\n",
      "702/702 [==============================] - 0s 270us/step - loss: 24.2838 - acc: 0.0271 - val_loss: 17.6140 - val_acc: 0.0299\n",
      "Epoch 8/200\n",
      "702/702 [==============================] - 0s 258us/step - loss: 24.3790 - acc: 0.0242 - val_loss: 16.2160 - val_acc: 0.0171\n",
      "Epoch 9/200\n",
      "702/702 [==============================] - 0s 268us/step - loss: 24.3373 - acc: 0.0413 - val_loss: 17.2802 - val_acc: 0.0214\n",
      "Epoch 10/200\n",
      "702/702 [==============================] - 0s 300us/step - loss: 24.3207 - acc: 0.0385 - val_loss: 16.9693 - val_acc: 0.0299\n",
      "Epoch 11/200\n",
      "702/702 [==============================] - 0s 282us/step - loss: 24.3411 - acc: 0.0399 - val_loss: 16.7967 - val_acc: 0.0214\n",
      "Epoch 12/200\n",
      "702/702 [==============================] - 0s 282us/step - loss: 24.3041 - acc: 0.0370 - val_loss: 16.1935 - val_acc: 0.0171\n",
      "Epoch 13/200\n",
      "702/702 [==============================] - 0s 322us/step - loss: 24.3062 - acc: 0.0328 - val_loss: 17.1400 - val_acc: 0.0299\n",
      "Epoch 14/200\n",
      "702/702 [==============================] - 0s 309us/step - loss: 24.2851 - acc: 0.0328 - val_loss: 18.1600 - val_acc: 0.0085\n",
      "Epoch 15/200\n",
      "702/702 [==============================] - 0s 295us/step - loss: 24.3103 - acc: 0.0228 - val_loss: 17.4552 - val_acc: 0.0171\n",
      "Epoch 16/200\n",
      "702/702 [==============================] - 0s 287us/step - loss: 24.3207 - acc: 0.0214 - val_loss: 17.1356 - val_acc: 0.0256\n",
      "Epoch 17/200\n",
      "702/702 [==============================] - 0s 268us/step - loss: 24.3027 - acc: 0.0313 - val_loss: 17.1967 - val_acc: 0.0299\n",
      "Epoch 18/200\n",
      "702/702 [==============================] - 0s 262us/step - loss: 24.3416 - acc: 0.0313 - val_loss: 17.1961 - val_acc: 0.0214\n",
      "Epoch 19/200\n",
      "702/702 [==============================] - 0s 264us/step - loss: 24.2574 - acc: 0.0313 - val_loss: 18.9122 - val_acc: 0.0171\n",
      "Epoch 20/200\n",
      "702/702 [==============================] - 0s 267us/step - loss: 24.3907 - acc: 0.0256 - val_loss: 18.1995 - val_acc: 0.0214\n",
      "Epoch 21/200\n",
      "702/702 [==============================] - 0s 275us/step - loss: 24.2688 - acc: 0.0356 - val_loss: 18.8447 - val_acc: 0.0256\n",
      "Epoch 22/200\n",
      "702/702 [==============================] - 0s 276us/step - loss: 24.3092 - acc: 0.0299 - val_loss: 17.3594 - val_acc: 0.0256\n",
      "Epoch 23/200\n",
      "702/702 [==============================] - 0s 308us/step - loss: 24.3480 - acc: 0.0256 - val_loss: 17.4453 - val_acc: 0.0214\n",
      "Epoch 24/200\n",
      "702/702 [==============================] - 0s 319us/step - loss: 24.3052 - acc: 0.0299 - val_loss: 16.4637 - val_acc: 0.0171\n",
      "Epoch 25/200\n",
      "702/702 [==============================] - 0s 377us/step - loss: 24.3174 - acc: 0.0328 - val_loss: 17.4875 - val_acc: 0.0214\n",
      "Epoch 26/200\n",
      "702/702 [==============================] - 0s 326us/step - loss: 24.2916 - acc: 0.0271 - val_loss: 17.4803 - val_acc: 0.0256\n",
      "Epoch 27/200\n",
      "702/702 [==============================] - 0s 399us/step - loss: 24.2756 - acc: 0.0228 - val_loss: 16.3792 - val_acc: 0.0214\n",
      "Epoch 28/200\n",
      "702/702 [==============================] - 0s 433us/step - loss: 24.3062 - acc: 0.0385 - val_loss: 18.0527 - val_acc: 0.0128\n",
      "Epoch 29/200\n",
      "702/702 [==============================] - 0s 373us/step - loss: 24.2596 - acc: 0.0328 - val_loss: 16.6648 - val_acc: 0.0128\n",
      "Epoch 30/200\n",
      "702/702 [==============================] - 0s 380us/step - loss: 24.2538 - acc: 0.0342 - val_loss: 16.4427 - val_acc: 0.0171\n",
      "Epoch 31/200\n",
      "702/702 [==============================] - 0s 306us/step - loss: 24.2713 - acc: 0.0185 - val_loss: 17.8522 - val_acc: 0.0043\n",
      "Epoch 32/200\n",
      "702/702 [==============================] - 0s 317us/step - loss: 24.2655 - acc: 0.0228 - val_loss: 16.9995 - val_acc: 0.0171\n",
      "Epoch 33/200\n",
      "702/702 [==============================] - 0s 385us/step - loss: 24.2633 - acc: 0.0271 - val_loss: 16.9547 - val_acc: 0.0171\n",
      "Epoch 34/200\n",
      "702/702 [==============================] - 0s 361us/step - loss: 24.2835 - acc: 0.0313 - val_loss: 16.2017 - val_acc: 0.0171\n",
      "Epoch 35/200\n",
      "702/702 [==============================] - 0s 387us/step - loss: 24.2626 - acc: 0.0356 - val_loss: 17.7839 - val_acc: 0.0256\n",
      "Epoch 36/200\n",
      "702/702 [==============================] - 0s 477us/step - loss: 24.2465 - acc: 0.0399 - val_loss: 17.3790 - val_acc: 0.0214\n",
      "Epoch 37/200\n",
      "702/702 [==============================] - 0s 349us/step - loss: 24.3027 - acc: 0.0271 - val_loss: 17.2776 - val_acc: 0.0256\n",
      "Epoch 38/200\n",
      "702/702 [==============================] - 0s 308us/step - loss: 24.3677 - acc: 0.0313 - val_loss: 17.4064 - val_acc: 0.0128\n",
      "Epoch 39/200\n",
      "702/702 [==============================] - 0s 457us/step - loss: 24.2732 - acc: 0.0370 - val_loss: 18.1256 - val_acc: 0.0128\n",
      "Epoch 40/200\n",
      "702/702 [==============================] - 0s 308us/step - loss: 24.3524 - acc: 0.0242 - val_loss: 17.1732 - val_acc: 0.0256\n",
      "Epoch 41/200\n",
      "702/702 [==============================] - 0s 398us/step - loss: 24.2702 - acc: 0.0256 - val_loss: 17.7894 - val_acc: 0.0085\n",
      "Epoch 42/200\n",
      "702/702 [==============================] - 0s 417us/step - loss: 24.2872 - acc: 0.0285 - val_loss: 16.8023 - val_acc: 0.0171\n",
      "Epoch 43/200\n",
      "702/702 [==============================] - 0s 386us/step - loss: 24.3293 - acc: 0.0356 - val_loss: 17.8366 - val_acc: 0.0214\n",
      "Epoch 44/200\n",
      "702/702 [==============================] - 0s 356us/step - loss: 24.2465 - acc: 0.0271 - val_loss: 17.2141 - val_acc: 0.0214\n",
      "Epoch 45/200\n",
      "702/702 [==============================] - 0s 322us/step - loss: 24.2442 - acc: 0.0285 - val_loss: 18.1742 - val_acc: 0.0214\n",
      "Epoch 46/200\n",
      "702/702 [==============================] - 0s 466us/step - loss: 24.3379 - acc: 0.0242 - val_loss: 17.4189 - val_acc: 0.0214\n",
      "Epoch 47/200\n",
      "702/702 [==============================] - 0s 541us/step - loss: 24.3121 - acc: 0.0299 - val_loss: 16.7382 - val_acc: 0.0214\n",
      "Epoch 48/200\n",
      "702/702 [==============================] - 0s 297us/step - loss: 24.2702 - acc: 0.0271 - val_loss: 18.5240 - val_acc: 0.0128\n",
      "Epoch 49/200\n",
      "702/702 [==============================] - 0s 307us/step - loss: 24.3209 - acc: 0.0285 - val_loss: 16.1199 - val_acc: 0.0342\n",
      "Epoch 50/200\n",
      "702/702 [==============================] - 0s 311us/step - loss: 24.3344 - acc: 0.0157 - val_loss: 17.4018 - val_acc: 0.0128\n",
      "Epoch 51/200\n",
      "702/702 [==============================] - 0s 286us/step - loss: 24.2729 - acc: 0.0242 - val_loss: 17.1599 - val_acc: 0.0256\n",
      "Epoch 52/200\n",
      "702/702 [==============================] - 0s 307us/step - loss: 24.2628 - acc: 0.0356 - val_loss: 16.6244 - val_acc: 0.0214\n",
      "Epoch 53/200\n",
      "702/702 [==============================] - 0s 296us/step - loss: 24.2845 - acc: 0.0242 - val_loss: 17.6431 - val_acc: 0.0214\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 54/200\n",
      "702/702 [==============================] - 0s 593us/step - loss: 24.2661 - acc: 0.0271 - val_loss: 16.8566 - val_acc: 0.0085\n",
      "Epoch 55/200\n",
      "702/702 [==============================] - 0s 620us/step - loss: 24.2499 - acc: 0.0285 - val_loss: 17.1345 - val_acc: 0.0214\n",
      "Epoch 56/200\n",
      "702/702 [==============================] - 0s 548us/step - loss: 24.2809 - acc: 0.0299 - val_loss: 17.8821 - val_acc: 0.0085\n",
      "Epoch 57/200\n",
      "702/702 [==============================] - 0s 548us/step - loss: 24.2839 - acc: 0.0328 - val_loss: 16.8468 - val_acc: 0.0171\n",
      "Epoch 58/200\n",
      "702/702 [==============================] - 0s 377us/step - loss: 24.2275 - acc: 0.0427 - val_loss: 16.6959 - val_acc: 0.0043\n",
      "Epoch 59/200\n",
      "702/702 [==============================] - 0s 393us/step - loss: 24.2369 - acc: 0.0228 - val_loss: 16.6499 - val_acc: 0.0171\n",
      "Epoch 60/200\n",
      "702/702 [==============================] - 0s 556us/step - loss: 24.2520 - acc: 0.0328 - val_loss: 17.7165 - val_acc: 0.0043\n",
      "Epoch 61/200\n",
      "702/702 [==============================] - 0s 624us/step - loss: 24.2565 - acc: 0.0342 - val_loss: 17.2593 - val_acc: 0.0299\n",
      "Epoch 62/200\n",
      "702/702 [==============================] - 0s 553us/step - loss: 24.3509 - acc: 0.0342 - val_loss: 17.2920 - val_acc: 0.0256\n",
      "Epoch 63/200\n",
      "702/702 [==============================] - 0s 607us/step - loss: 24.2995 - acc: 0.0256 - val_loss: 16.5656 - val_acc: 0.0171\n",
      "Epoch 64/200\n",
      "702/702 [==============================] - 0s 542us/step - loss: 24.2724 - acc: 0.0370 - val_loss: 17.1391 - val_acc: 0.0256\n",
      "Epoch 65/200\n",
      "702/702 [==============================] - 0s 358us/step - loss: 24.2348 - acc: 0.0470 - val_loss: 17.4793 - val_acc: 0.0256\n",
      "Epoch 66/200\n",
      "702/702 [==============================] - 0s 316us/step - loss: 24.2559 - acc: 0.0370 - val_loss: 16.6157 - val_acc: 0.0171\n",
      "Epoch 67/200\n",
      "702/702 [==============================] - 0s 411us/step - loss: 24.3551 - acc: 0.0228 - val_loss: 17.0212 - val_acc: 0.0128\n",
      "Epoch 68/200\n",
      "702/702 [==============================] - 0s 302us/step - loss: 24.2068 - acc: 0.0214 - val_loss: 17.5376 - val_acc: 0.0128\n",
      "Epoch 69/200\n",
      "702/702 [==============================] - 0s 319us/step - loss: 24.2571 - acc: 0.0313 - val_loss: 17.8997 - val_acc: 0.0214\n",
      "Epoch 70/200\n",
      "702/702 [==============================] - 0s 284us/step - loss: 24.2682 - acc: 0.0342 - val_loss: 17.0137 - val_acc: 0.0299\n",
      "Epoch 71/200\n",
      "702/702 [==============================] - 0s 268us/step - loss: 24.2192 - acc: 0.0242 - val_loss: 15.8689 - val_acc: 0.0256\n",
      "Epoch 72/200\n",
      "702/702 [==============================] - 0s 413us/step - loss: 24.3247 - acc: 0.0214 - val_loss: 16.9497 - val_acc: 0.0128\n",
      "Epoch 73/200\n",
      "702/702 [==============================] - 0s 263us/step - loss: 24.2156 - acc: 0.0413 - val_loss: 17.9031 - val_acc: 0.0214\n",
      "Epoch 74/200\n",
      "702/702 [==============================] - 0s 338us/step - loss: 24.2995 - acc: 0.0285 - val_loss: 17.0744 - val_acc: 0.0214\n",
      "Epoch 75/200\n",
      "702/702 [==============================] - 0s 414us/step - loss: 24.2789 - acc: 0.0370 - val_loss: 18.2002 - val_acc: 0.0128\n",
      "Epoch 76/200\n",
      "702/702 [==============================] - 0s 427us/step - loss: 24.2825 - acc: 0.0285 - val_loss: 17.0322 - val_acc: 0.0256\n",
      "Epoch 77/200\n",
      "702/702 [==============================] - 0s 522us/step - loss: 24.2733 - acc: 0.0313 - val_loss: 16.3518 - val_acc: 0.0128\n",
      "Epoch 78/200\n",
      "702/702 [==============================] - 0s 273us/step - loss: 24.2680 - acc: 0.0427 - val_loss: 17.7850 - val_acc: 0.0085\n",
      "Epoch 79/200\n",
      "702/702 [==============================] - 0s 272us/step - loss: 24.3456 - acc: 0.0214 - val_loss: 16.5650 - val_acc: 0.0171\n",
      "Epoch 80/200\n",
      "702/702 [==============================] - 0s 274us/step - loss: 24.2495 - acc: 0.0299 - val_loss: 17.0072 - val_acc: 0.0214\n",
      "Epoch 81/200\n",
      "702/702 [==============================] - 0s 298us/step - loss: 24.3218 - acc: 0.0256 - val_loss: 16.4921 - val_acc: 0.0214\n",
      "Epoch 82/200\n",
      "702/702 [==============================] - 0s 355us/step - loss: 24.2250 - acc: 0.0399 - val_loss: 17.6025 - val_acc: 0.0299\n",
      "Epoch 83/200\n",
      "702/702 [==============================] - 0s 299us/step - loss: 24.2654 - acc: 0.0328 - val_loss: 16.5802 - val_acc: 0.0214\n",
      "Epoch 84/200\n",
      "702/702 [==============================] - 0s 463us/step - loss: 24.2418 - acc: 0.0271 - val_loss: 17.0659 - val_acc: 0.0256\n",
      "Epoch 85/200\n",
      "702/702 [==============================] - 0s 665us/step - loss: 24.3050 - acc: 0.0356 - val_loss: 16.9447 - val_acc: 0.0128\n",
      "Epoch 86/200\n",
      "702/702 [==============================] - 0s 379us/step - loss: 24.2664 - acc: 0.0356 - val_loss: 16.6585 - val_acc: 0.0171\n",
      "Epoch 87/200\n",
      "702/702 [==============================] - 0s 410us/step - loss: 24.2491 - acc: 0.0271 - val_loss: 17.4390 - val_acc: 0.0085\n",
      "Epoch 88/200\n",
      "702/702 [==============================] - 0s 255us/step - loss: 24.2550 - acc: 0.0399 - val_loss: 16.8554 - val_acc: 0.0128\n",
      "Epoch 89/200\n",
      "702/702 [==============================] - 0s 271us/step - loss: 24.2507 - acc: 0.0413 - val_loss: 16.1981 - val_acc: 0.0256\n",
      "Epoch 90/200\n",
      "702/702 [==============================] - 0s 329us/step - loss: 24.2816 - acc: 0.0256 - val_loss: 16.8059 - val_acc: 0.0256\n",
      "Epoch 91/200\n",
      "702/702 [==============================] - 0s 364us/step - loss: 24.1813 - acc: 0.0214 - val_loss: 16.8024 - val_acc: 0.0256\n",
      "Epoch 92/200\n",
      "702/702 [==============================] - 0s 561us/step - loss: 24.2624 - acc: 0.0171 - val_loss: 17.3434 - val_acc: 0.0214\n",
      "Epoch 93/200\n",
      "702/702 [==============================] - 0s 357us/step - loss: 24.2647 - acc: 0.0256 - val_loss: 16.0344 - val_acc: 0.0256\n",
      "Epoch 94/200\n",
      "702/702 [==============================] - 0s 416us/step - loss: 24.3281 - acc: 0.0285 - val_loss: 17.3670 - val_acc: 0.0171\n",
      "Epoch 95/200\n",
      "702/702 [==============================] - 0s 485us/step - loss: 24.2653 - acc: 0.0356 - val_loss: 17.3978 - val_acc: 0.0171\n",
      "Epoch 96/200\n",
      "702/702 [==============================] - 0s 542us/step - loss: 24.2970 - acc: 0.0342 - val_loss: 16.7084 - val_acc: 0.0085\n",
      "Epoch 97/200\n",
      "702/702 [==============================] - 0s 322us/step - loss: 24.1932 - acc: 0.0370 - val_loss: 18.5702 - val_acc: 0.0171\n",
      "Epoch 98/200\n",
      "702/702 [==============================] - 0s 272us/step - loss: 24.3113 - acc: 0.0313 - val_loss: 17.6442 - val_acc: 0.0256\n",
      "Epoch 99/200\n",
      "702/702 [==============================] - 0s 262us/step - loss: 24.2945 - acc: 0.0342 - val_loss: 16.4221 - val_acc: 0.0256\n",
      "Epoch 100/200\n",
      "702/702 [==============================] - 0s 268us/step - loss: 24.2320 - acc: 0.0285 - val_loss: 16.6015 - val_acc: 0.0085\n",
      "Epoch 101/200\n",
      "702/702 [==============================] - 0s 234us/step - loss: 24.2673 - acc: 0.0299 - val_loss: 17.1413 - val_acc: 0.0214\n",
      "Epoch 102/200\n",
      "702/702 [==============================] - 0s 225us/step - loss: 24.2456 - acc: 0.0385 - val_loss: 16.7428 - val_acc: 0.0128\n",
      "Epoch 103/200\n",
      "702/702 [==============================] - 0s 228us/step - loss: 24.2404 - acc: 0.0427 - val_loss: 17.3175 - val_acc: 0.0171\n",
      "Epoch 104/200\n",
      "702/702 [==============================] - 0s 224us/step - loss: 24.2746 - acc: 0.0342 - val_loss: 17.3598 - val_acc: 0.0214\n",
      "Epoch 105/200\n",
      "702/702 [==============================] - 0s 222us/step - loss: 24.2698 - acc: 0.0242 - val_loss: 16.4938 - val_acc: 0.0299\n",
      "Epoch 106/200\n",
      "702/702 [==============================] - 0s 323us/step - loss: 24.2671 - acc: 0.0356 - val_loss: 17.1303 - val_acc: 0.0256\n",
      "Epoch 107/200\n",
      "702/702 [==============================] - 0s 343us/step - loss: 24.2449 - acc: 0.0399 - val_loss: 17.4833 - val_acc: 0.0214\n",
      "Epoch 108/200\n",
      "702/702 [==============================] - 0s 294us/step - loss: 24.2622 - acc: 0.0313 - val_loss: 16.9406 - val_acc: 0.0256\n",
      "Epoch 109/200\n",
      "702/702 [==============================] - 0s 278us/step - loss: 24.2287 - acc: 0.0256 - val_loss: 16.3818 - val_acc: 0.0214\n",
      "Epoch 110/200\n",
      "702/702 [==============================] - 0s 307us/step - loss: 24.2929 - acc: 0.0456 - val_loss: 16.5413 - val_acc: 0.0128\n",
      "Epoch 111/200\n",
      "702/702 [==============================] - 0s 267us/step - loss: 24.2710 - acc: 0.0299 - val_loss: 16.9071 - val_acc: 0.0214\n",
      "Epoch 112/200\n",
      "702/702 [==============================] - 0s 229us/step - loss: 24.3078 - acc: 0.0256 - val_loss: 18.0304 - val_acc: 0.0214\n",
      "Epoch 113/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "702/702 [==============================] - 0s 400us/step - loss: 24.2765 - acc: 0.0199 - val_loss: 16.7114 - val_acc: 0.0256\n",
      "Epoch 114/200\n",
      "702/702 [==============================] - 0s 389us/step - loss: 24.2765 - acc: 0.0285 - val_loss: 16.8425 - val_acc: 0.0214\n",
      "Epoch 115/200\n",
      "702/702 [==============================] - 0s 340us/step - loss: 24.2578 - acc: 0.0342 - val_loss: 17.0155 - val_acc: 0.0171\n",
      "Epoch 116/200\n",
      "702/702 [==============================] - 0s 360us/step - loss: 24.2859 - acc: 0.0399 - val_loss: 17.6059 - val_acc: 0.0171\n",
      "Epoch 117/200\n",
      "702/702 [==============================] - 0s 503us/step - loss: 24.2568 - acc: 0.0385 - val_loss: 16.6663 - val_acc: 0.0171\n",
      "Epoch 118/200\n",
      "702/702 [==============================] - 0s 454us/step - loss: 24.2306 - acc: 0.0413 - val_loss: 18.2015 - val_acc: 0.0128\n",
      "Epoch 119/200\n",
      "702/702 [==============================] - 0s 435us/step - loss: 24.2904 - acc: 0.0171 - val_loss: 17.0149 - val_acc: 0.0171\n",
      "Epoch 120/200\n",
      "702/702 [==============================] - 0s 322us/step - loss: 24.2622 - acc: 0.0370 - val_loss: 16.4651 - val_acc: 0.0128\n",
      "Epoch 121/200\n",
      "702/702 [==============================] - 0s 390us/step - loss: 24.2170 - acc: 0.0299 - val_loss: 17.9532 - val_acc: 0.0256\n",
      "Epoch 122/200\n",
      "702/702 [==============================] - 0s 470us/step - loss: 24.2670 - acc: 0.0185 - val_loss: 17.6645 - val_acc: 0.0171\n",
      "Epoch 123/200\n",
      "702/702 [==============================] - 0s 440us/step - loss: 24.2878 - acc: 0.0356 - val_loss: 16.7384 - val_acc: 0.0128\n",
      "Epoch 124/200\n",
      "702/702 [==============================] - 0s 476us/step - loss: 24.2618 - acc: 0.0413 - val_loss: 17.2457 - val_acc: 0.0214\n",
      "Epoch 125/200\n",
      "702/702 [==============================] - 0s 402us/step - loss: 24.3514 - acc: 0.0285 - val_loss: 16.9145 - val_acc: 0.0128\n",
      "Epoch 126/200\n",
      "702/702 [==============================] - 0s 275us/step - loss: 24.2389 - acc: 0.0342 - val_loss: 16.6064 - val_acc: 0.0043\n",
      "Epoch 127/200\n",
      "702/702 [==============================] - ETA: 0s - loss: 24.3815 - acc: 0.03 - 0s 293us/step - loss: 24.2279 - acc: 0.0313 - val_loss: 17.6563 - val_acc: 0.0171\n",
      "Epoch 128/200\n",
      "702/702 [==============================] - 0s 272us/step - loss: 24.2414 - acc: 0.0285 - val_loss: 16.8969 - val_acc: 0.0171\n",
      "Epoch 129/200\n",
      "702/702 [==============================] - 0s 295us/step - loss: 24.2507 - acc: 0.0370 - val_loss: 17.0177 - val_acc: 0.0256\n",
      "Epoch 130/200\n",
      "702/702 [==============================] - 0s 285us/step - loss: 24.2257 - acc: 0.0285 - val_loss: 17.6408 - val_acc: 0.0214\n",
      "Epoch 131/200\n",
      "702/702 [==============================] - 0s 239us/step - loss: 24.2424 - acc: 0.0328 - val_loss: 17.5590 - val_acc: 0.0128\n",
      "Epoch 132/200\n",
      "702/702 [==============================] - 0s 279us/step - loss: 24.2546 - acc: 0.0442 - val_loss: 17.3318 - val_acc: 0.0299\n",
      "Epoch 133/200\n",
      "702/702 [==============================] - 0s 332us/step - loss: 24.2906 - acc: 0.0328 - val_loss: 17.5705 - val_acc: 0.0171\n",
      "Epoch 134/200\n",
      "702/702 [==============================] - 0s 408us/step - loss: 24.2490 - acc: 0.0242 - val_loss: 17.0864 - val_acc: 0.0214\n",
      "Epoch 135/200\n",
      "702/702 [==============================] - 0s 339us/step - loss: 24.2377 - acc: 0.0385 - val_loss: 17.5402 - val_acc: 0.0214\n",
      "Epoch 136/200\n",
      "702/702 [==============================] - 0s 256us/step - loss: 24.2671 - acc: 0.0313 - val_loss: 16.9174 - val_acc: 0.0256\n",
      "Epoch 137/200\n",
      "702/702 [==============================] - 0s 242us/step - loss: 24.2330 - acc: 0.0242 - val_loss: 16.4287 - val_acc: 0.0128\n",
      "Epoch 138/200\n",
      "702/702 [==============================] - 0s 346us/step - loss: 24.3660 - acc: 0.0299 - val_loss: 17.5096 - val_acc: 0.0171\n",
      "Epoch 139/200\n",
      "702/702 [==============================] - 0s 277us/step - loss: 24.2674 - acc: 0.0242 - val_loss: 17.2279 - val_acc: 0.0299\n",
      "Epoch 140/200\n",
      "702/702 [==============================] - 0s 250us/step - loss: 24.2908 - acc: 0.0342 - val_loss: 17.9765 - val_acc: 0.0085\n",
      "Epoch 141/200\n",
      "702/702 [==============================] - 0s 367us/step - loss: 24.2702 - acc: 0.0385 - val_loss: 18.2994 - val_acc: 0.0128\n",
      "Epoch 142/200\n",
      "702/702 [==============================] - 0s 283us/step - loss: 24.2375 - acc: 0.0342 - val_loss: 16.9805 - val_acc: 0.0214\n",
      "Epoch 143/200\n",
      "702/702 [==============================] - 0s 244us/step - loss: 24.2527 - acc: 0.0442 - val_loss: 17.3257 - val_acc: 0.0214\n",
      "Epoch 144/200\n",
      "702/702 [==============================] - 0s 325us/step - loss: 24.3219 - acc: 0.0228 - val_loss: 17.1880 - val_acc: 0.0128\n",
      "Epoch 145/200\n",
      "702/702 [==============================] - 0s 331us/step - loss: 24.2251 - acc: 0.0285 - val_loss: 16.6898 - val_acc: 0.0214\n",
      "Epoch 146/200\n",
      "702/702 [==============================] - 0s 241us/step - loss: 24.2526 - acc: 0.0385 - val_loss: 16.8994 - val_acc: 0.0171\n",
      "Epoch 147/200\n",
      "702/702 [==============================] - 0s 266us/step - loss: 24.1426 - acc: 0.0470 - val_loss: 18.3101 - val_acc: 0.0128\n",
      "Epoch 148/200\n",
      "702/702 [==============================] - 0s 259us/step - loss: 24.2964 - acc: 0.0370 - val_loss: 16.7066 - val_acc: 0.0171\n",
      "Epoch 149/200\n",
      "702/702 [==============================] - 0s 253us/step - loss: 24.2995 - acc: 0.0356 - val_loss: 17.4103 - val_acc: 0.0128\n",
      "Epoch 150/200\n",
      "702/702 [==============================] - 0s 217us/step - loss: 24.2561 - acc: 0.0356 - val_loss: 17.3603 - val_acc: 0.0214\n",
      "Epoch 151/200\n",
      "702/702 [==============================] - 0s 288us/step - loss: 24.2797 - acc: 0.0256 - val_loss: 17.8694 - val_acc: 0.0128\n",
      "Epoch 152/200\n",
      "702/702 [==============================] - 0s 236us/step - loss: 24.2343 - acc: 0.0385 - val_loss: 18.3666 - val_acc: 0.0043\n",
      "Epoch 153/200\n",
      "702/702 [==============================] - 0s 272us/step - loss: 24.2606 - acc: 0.0313 - val_loss: 16.9770 - val_acc: 0.0171\n",
      "Epoch 154/200\n",
      "702/702 [==============================] - 0s 278us/step - loss: 24.2490 - acc: 0.0271 - val_loss: 17.1530 - val_acc: 0.0256\n",
      "Epoch 155/200\n",
      "702/702 [==============================] - 0s 301us/step - loss: 24.2376 - acc: 0.0399 - val_loss: 17.1972 - val_acc: 0.0171\n",
      "Epoch 156/200\n",
      "702/702 [==============================] - 0s 255us/step - loss: 24.2008 - acc: 0.0299 - val_loss: 17.9355 - val_acc: 0.0171\n",
      "Epoch 157/200\n",
      "702/702 [==============================] - 0s 314us/step - loss: 24.2450 - acc: 0.0370 - val_loss: 17.3305 - val_acc: 0.0214\n",
      "Epoch 158/200\n",
      "702/702 [==============================] - 0s 309us/step - loss: 24.2183 - acc: 0.0256 - val_loss: 16.2273 - val_acc: 0.0171\n",
      "Epoch 159/200\n",
      "702/702 [==============================] - 0s 232us/step - loss: 24.2233 - acc: 0.0370 - val_loss: 17.9860 - val_acc: 0.0256\n",
      "Epoch 160/200\n",
      "702/702 [==============================] - 0s 224us/step - loss: 24.2381 - acc: 0.0228 - val_loss: 16.2715 - val_acc: 0.0214\n",
      "Epoch 161/200\n",
      "702/702 [==============================] - 0s 370us/step - loss: 24.2318 - acc: 0.0370 - val_loss: 17.2343 - val_acc: 0.0128\n",
      "Epoch 162/200\n",
      "702/702 [==============================] - 0s 322us/step - loss: 24.2527 - acc: 0.0299 - val_loss: 17.3608 - val_acc: 0.0299\n",
      "Epoch 163/200\n",
      "702/702 [==============================] - 0s 284us/step - loss: 24.2393 - acc: 0.0413 - val_loss: 17.7779 - val_acc: 0.0171\n",
      "Epoch 164/200\n",
      "702/702 [==============================] - 0s 267us/step - loss: 24.2361 - acc: 0.0242 - val_loss: 17.2344 - val_acc: 0.0214\n",
      "Epoch 165/200\n",
      "702/702 [==============================] - 0s 366us/step - loss: 24.2529 - acc: 0.0299 - val_loss: 17.0598 - val_acc: 0.0128\n",
      "Epoch 166/200\n",
      "702/702 [==============================] - 0s 345us/step - loss: 24.2302 - acc: 0.0271 - val_loss: 16.9345 - val_acc: 0.0214\n",
      "Epoch 167/200\n",
      "702/702 [==============================] - 0s 442us/step - loss: 24.2228 - acc: 0.0285 - val_loss: 16.1023 - val_acc: 0.0085\n",
      "Epoch 168/200\n",
      "702/702 [==============================] - 0s 480us/step - loss: 24.3415 - acc: 0.0242 - val_loss: 16.7664 - val_acc: 0.0128\n",
      "Epoch 169/200\n",
      "702/702 [==============================] - 0s 442us/step - loss: 24.2446 - acc: 0.0285 - val_loss: 17.6093 - val_acc: 0.0256\n",
      "Epoch 170/200\n",
      "702/702 [==============================] - 0s 308us/step - loss: 24.2065 - acc: 0.0313 - val_loss: 17.8110 - val_acc: 0.0214\n",
      "Epoch 171/200\n",
      "702/702 [==============================] - 0s 466us/step - loss: 24.1842 - acc: 0.0285 - val_loss: 16.8691 - val_acc: 0.0214\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 172/200\n",
      "702/702 [==============================] - 0s 457us/step - loss: 24.1940 - acc: 0.0256 - val_loss: 18.0849 - val_acc: 0.0085\n",
      "Epoch 173/200\n",
      "702/702 [==============================] - 0s 406us/step - loss: 24.2507 - acc: 0.0256 - val_loss: 16.9019 - val_acc: 0.0128\n",
      "Epoch 174/200\n",
      "702/702 [==============================] - 0s 309us/step - loss: 24.2536 - acc: 0.0356 - val_loss: 17.1395 - val_acc: 0.0171\n",
      "Epoch 175/200\n",
      "702/702 [==============================] - 0s 355us/step - loss: 24.2233 - acc: 0.0328 - val_loss: 17.6394 - val_acc: 0.0128\n",
      "Epoch 176/200\n",
      "702/702 [==============================] - 0s 269us/step - loss: 24.2693 - acc: 0.0299 - val_loss: 16.9272 - val_acc: 0.0214\n",
      "Epoch 177/200\n",
      "702/702 [==============================] - 0s 266us/step - loss: 24.2896 - acc: 0.0313 - val_loss: 16.7007 - val_acc: 0.0128\n",
      "Epoch 178/200\n",
      "702/702 [==============================] - 0s 273us/step - loss: 24.2586 - acc: 0.0342 - val_loss: 17.1807 - val_acc: 0.0128\n",
      "Epoch 179/200\n",
      "702/702 [==============================] - 0s 220us/step - loss: 24.2442 - acc: 0.0342 - val_loss: 17.7456 - val_acc: 0.0299\n",
      "Epoch 180/200\n",
      "702/702 [==============================] - 0s 220us/step - loss: 24.2113 - acc: 0.0285 - val_loss: 16.9045 - val_acc: 0.0128\n",
      "Epoch 181/200\n",
      "702/702 [==============================] - 0s 236us/step - loss: 24.2580 - acc: 0.0299 - val_loss: 17.5821 - val_acc: 0.0128\n",
      "Epoch 182/200\n",
      "702/702 [==============================] - 0s 221us/step - loss: 24.2587 - acc: 0.0328 - val_loss: 16.8987 - val_acc: 0.0128\n",
      "Epoch 183/200\n",
      "702/702 [==============================] - 0s 300us/step - loss: 24.2096 - acc: 0.0470 - val_loss: 16.6012 - val_acc: 0.0128\n",
      "Epoch 184/200\n",
      "702/702 [==============================] - 0s 313us/step - loss: 24.3224 - acc: 0.0356 - val_loss: 17.4001 - val_acc: 0.0171\n",
      "Epoch 185/200\n",
      "702/702 [==============================] - 0s 282us/step - loss: 24.2181 - acc: 0.0271 - val_loss: 16.6537 - val_acc: 0.0214\n",
      "Epoch 186/200\n",
      "702/702 [==============================] - 0s 284us/step - loss: 24.2514 - acc: 0.0385 - val_loss: 17.3467 - val_acc: 0.0214\n",
      "Epoch 187/200\n",
      "702/702 [==============================] - 0s 340us/step - loss: 24.2388 - acc: 0.0299 - val_loss: 17.0965 - val_acc: 0.0171\n",
      "Epoch 188/200\n",
      "702/702 [==============================] - 0s 237us/step - loss: 24.2187 - acc: 0.0299 - val_loss: 18.0688 - val_acc: 0.0256\n",
      "Epoch 189/200\n",
      "702/702 [==============================] - 0s 323us/step - loss: 24.2332 - acc: 0.0328 - val_loss: 17.7941 - val_acc: 0.0214\n",
      "Epoch 190/200\n",
      "702/702 [==============================] - 0s 313us/step - loss: 24.2743 - acc: 0.0271 - val_loss: 17.3133 - val_acc: 0.0171\n",
      "Epoch 191/200\n",
      "702/702 [==============================] - 0s 236us/step - loss: 24.2707 - acc: 0.0299 - val_loss: 16.8487 - val_acc: 0.0256\n",
      "Epoch 192/200\n",
      "702/702 [==============================] - 0s 363us/step - loss: 24.2517 - acc: 0.0342 - val_loss: 17.3026 - val_acc: 0.0214\n",
      "Epoch 193/200\n",
      "702/702 [==============================] - 0s 397us/step - loss: 24.2660 - acc: 0.0356 - val_loss: 17.1089 - val_acc: 0.0128\n",
      "Epoch 194/200\n",
      "702/702 [==============================] - 0s 291us/step - loss: 24.2621 - acc: 0.0413 - val_loss: 16.9914 - val_acc: 0.0214\n",
      "Epoch 195/200\n",
      "702/702 [==============================] - 0s 267us/step - loss: 24.1972 - acc: 0.0299 - val_loss: 16.4458 - val_acc: 0.0214\n",
      "Epoch 196/200\n",
      "702/702 [==============================] - 0s 281us/step - loss: 24.3283 - acc: 0.0342 - val_loss: 16.2754 - val_acc: 0.0214\n",
      "Epoch 197/200\n",
      "702/702 [==============================] - 0s 381us/step - loss: 24.2380 - acc: 0.0399 - val_loss: 17.1775 - val_acc: 0.0171\n",
      "Epoch 198/200\n",
      "702/702 [==============================] - 0s 286us/step - loss: 24.2487 - acc: 0.0299 - val_loss: 17.5161 - val_acc: 0.0128\n",
      "Epoch 199/200\n",
      "702/702 [==============================] - 0s 268us/step - loss: 24.2528 - acc: 0.0228 - val_loss: 17.0401 - val_acc: 0.0214\n",
      "Epoch 200/200\n",
      "702/702 [==============================] - 0s 301us/step - loss: 24.2702 - acc: 0.0242 - val_loss: 17.7576 - val_acc: 0.0256\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SJ : MAE : 17.757556030892918\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "\n",
    "sj_model = Sequential()\n",
    "sj_model.add(Dense(32, input_dim=sj_train_X.shape[1], kernel_initializer='normal'))\n",
    "sj_model.add(Dense(16, kernel_initializer='normal'))\n",
    "sj_model.add(Dense(8, kernel_initializer='normal'))\n",
    "sj_model.add(Dense(output_dim=1, kernel_initializer='normal', activation='relu'))\n",
    "\n",
    "sj_model.compile(loss='mean_absolute_error', optimizer='adam', metrics=['accuracy'])\n",
    "sj_model.summary()\n",
    "\n",
    "\n",
    "# ......train..............\n",
    "hist = sj_model.fit(sj_train_X, sj_train_y.values,\n",
    "          batch_size=5,\n",
    "          epochs=200,\n",
    "          validation_data=(sj_test_X, sj_test_y.values)\n",
    "            )\n",
    "plt.plot(hist.history['loss'], label='train')\n",
    "plt.plot(hist.history['val_loss'], label='test')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "sj_pred = sj_model.predict(sj_test_X)\n",
    "print(\"SJ : MAE : \" + str(mean_absolute_error(sj_test_y, sj_pred)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_5 (Dense)              (None, 8)                 96        \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 4)                 36        \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 2)                 10        \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 1)                 3         \n",
      "=================================================================\n",
      "Total params: 145\n",
      "Trainable params: 145\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:5: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(units=1, activation=\"relu\", kernel_initializer=\"normal\")`\n",
      "  \"\"\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 390 samples, validate on 130 samples\n",
      "Epoch 1/100\n",
      "390/390 [==============================] - 0s 570us/step - loss: 141.8328 - acc: 0.2179 - val_loss: 264.4039 - val_acc: 0.0846\n",
      "Epoch 2/100\n",
      "390/390 [==============================] - 0s 112us/step - loss: 141.1177 - acc: 0.2179 - val_loss: 262.8769 - val_acc: 0.0846\n",
      "Epoch 3/100\n",
      "390/390 [==============================] - 0s 123us/step - loss: 139.5807 - acc: 0.2179 - val_loss: 259.4056 - val_acc: 0.0846\n",
      "Epoch 4/100\n",
      "390/390 [==============================] - 0s 112us/step - loss: 136.0588 - acc: 0.2154 - val_loss: 250.7868 - val_acc: 0.1000\n",
      "Epoch 5/100\n",
      "390/390 [==============================] - 0s 110us/step - loss: 127.4261 - acc: 0.2000 - val_loss: 233.2597 - val_acc: 0.1000\n",
      "Epoch 6/100\n",
      "390/390 [==============================] - 0s 116us/step - loss: 114.3958 - acc: 0.1744 - val_loss: 210.8089 - val_acc: 0.1231\n",
      "Epoch 7/100\n",
      "390/390 [==============================] - 0s 111us/step - loss: 102.7339 - acc: 0.1769 - val_loss: 192.7554 - val_acc: 0.1000\n",
      "Epoch 8/100\n",
      "390/390 [==============================] - 0s 123us/step - loss: 96.8654 - acc: 0.1590 - val_loss: 183.0691 - val_acc: 0.0923\n",
      "Epoch 9/100\n",
      "390/390 [==============================] - 0s 112us/step - loss: 94.5080 - acc: 0.1513 - val_loss: 180.4939 - val_acc: 0.1077\n",
      "Epoch 10/100\n",
      "390/390 [==============================] - 0s 114us/step - loss: 93.6479 - acc: 0.1436 - val_loss: 177.7330 - val_acc: 0.1231\n",
      "Epoch 11/100\n",
      "390/390 [==============================] - 0s 116us/step - loss: 93.1050 - acc: 0.1410 - val_loss: 176.2911 - val_acc: 0.1154\n",
      "Epoch 12/100\n",
      "390/390 [==============================] - 0s 114us/step - loss: 92.5798 - acc: 0.1462 - val_loss: 174.0860 - val_acc: 0.1000\n",
      "Epoch 13/100\n",
      "390/390 [==============================] - 0s 114us/step - loss: 92.1058 - acc: 0.1538 - val_loss: 173.5236 - val_acc: 0.1000\n",
      "Epoch 14/100\n",
      "390/390 [==============================] - 0s 112us/step - loss: 91.5323 - acc: 0.1538 - val_loss: 172.6797 - val_acc: 0.1000\n",
      "Epoch 15/100\n",
      "390/390 [==============================] - 0s 116us/step - loss: 91.1996 - acc: 0.1487 - val_loss: 172.0691 - val_acc: 0.0846\n",
      "Epoch 16/100\n",
      "390/390 [==============================] - 0s 115us/step - loss: 91.0421 - acc: 0.1538 - val_loss: 171.9188 - val_acc: 0.0692\n",
      "Epoch 17/100\n",
      "390/390 [==============================] - 0s 115us/step - loss: 90.6324 - acc: 0.1513 - val_loss: 171.1244 - val_acc: 0.0615\n",
      "Epoch 18/100\n",
      "390/390 [==============================] - 0s 113us/step - loss: 90.2920 - acc: 0.1513 - val_loss: 170.7920 - val_acc: 0.0615\n",
      "Epoch 19/100\n",
      "390/390 [==============================] - 0s 117us/step - loss: 89.9993 - acc: 0.1410 - val_loss: 169.6928 - val_acc: 0.0846\n",
      "Epoch 20/100\n",
      "390/390 [==============================] - 0s 118us/step - loss: 89.6639 - acc: 0.1308 - val_loss: 169.5218 - val_acc: 0.1077\n",
      "Epoch 21/100\n",
      "390/390 [==============================] - 0s 114us/step - loss: 89.3091 - acc: 0.1282 - val_loss: 168.8337 - val_acc: 0.1077\n",
      "Epoch 22/100\n",
      "390/390 [==============================] - 0s 116us/step - loss: 89.1102 - acc: 0.1231 - val_loss: 168.3414 - val_acc: 0.1077\n",
      "Epoch 23/100\n",
      "390/390 [==============================] - 0s 113us/step - loss: 88.6939 - acc: 0.1205 - val_loss: 167.2485 - val_acc: 0.0846\n",
      "Epoch 24/100\n",
      "390/390 [==============================] - 0s 111us/step - loss: 88.6996 - acc: 0.1154 - val_loss: 166.3603 - val_acc: 0.0615\n",
      "Epoch 25/100\n",
      "390/390 [==============================] - 0s 115us/step - loss: 88.4261 - acc: 0.1000 - val_loss: 167.0129 - val_acc: 0.0615\n",
      "Epoch 26/100\n",
      "390/390 [==============================] - 0s 115us/step - loss: 88.2260 - acc: 0.1103 - val_loss: 166.5287 - val_acc: 0.0615\n",
      "Epoch 27/100\n",
      "390/390 [==============================] - 0s 120us/step - loss: 88.3806 - acc: 0.1103 - val_loss: 166.9132 - val_acc: 0.0846\n",
      "Epoch 28/100\n",
      "390/390 [==============================] - 0s 114us/step - loss: 88.0472 - acc: 0.1000 - val_loss: 166.7762 - val_acc: 0.0923\n",
      "Epoch 29/100\n",
      "390/390 [==============================] - 0s 117us/step - loss: 88.1752 - acc: 0.1000 - val_loss: 163.9187 - val_acc: 0.0769\n",
      "Epoch 30/100\n",
      "390/390 [==============================] - 0s 111us/step - loss: 87.4843 - acc: 0.0897 - val_loss: 165.0195 - val_acc: 0.0846\n",
      "Epoch 31/100\n",
      "390/390 [==============================] - 0s 115us/step - loss: 87.6355 - acc: 0.0897 - val_loss: 164.2135 - val_acc: 0.0846\n",
      "Epoch 32/100\n",
      "390/390 [==============================] - 0s 113us/step - loss: 87.5611 - acc: 0.0897 - val_loss: 163.8791 - val_acc: 0.0846\n",
      "Epoch 33/100\n",
      "390/390 [==============================] - 0s 114us/step - loss: 87.3671 - acc: 0.0897 - val_loss: 164.4877 - val_acc: 0.0846\n",
      "Epoch 34/100\n",
      "390/390 [==============================] - 0s 115us/step - loss: 87.4879 - acc: 0.0846 - val_loss: 164.5396 - val_acc: 0.0769\n",
      "Epoch 35/100\n",
      "390/390 [==============================] - 0s 113us/step - loss: 87.3696 - acc: 0.0846 - val_loss: 163.7754 - val_acc: 0.0769\n",
      "Epoch 36/100\n",
      "390/390 [==============================] - 0s 116us/step - loss: 87.3875 - acc: 0.0821 - val_loss: 162.7397 - val_acc: 0.0692\n",
      "Epoch 37/100\n",
      "390/390 [==============================] - 0s 114us/step - loss: 87.3702 - acc: 0.0769 - val_loss: 163.8797 - val_acc: 0.0692\n",
      "Epoch 38/100\n",
      "390/390 [==============================] - 0s 123us/step - loss: 87.4651 - acc: 0.0795 - val_loss: 163.5215 - val_acc: 0.0615\n",
      "Epoch 39/100\n",
      "390/390 [==============================] - 0s 114us/step - loss: 87.2648 - acc: 0.0821 - val_loss: 162.8965 - val_acc: 0.0538\n",
      "Epoch 40/100\n",
      "390/390 [==============================] - 0s 116us/step - loss: 87.3268 - acc: 0.0846 - val_loss: 162.5596 - val_acc: 0.0615\n",
      "Epoch 41/100\n",
      "390/390 [==============================] - 0s 173us/step - loss: 87.3924 - acc: 0.0846 - val_loss: 163.1846 - val_acc: 0.0538\n",
      "Epoch 42/100\n",
      "390/390 [==============================] - 0s 166us/step - loss: 87.3588 - acc: 0.0872 - val_loss: 162.4858 - val_acc: 0.0462\n",
      "Epoch 43/100\n",
      "390/390 [==============================] - 0s 143us/step - loss: 87.2694 - acc: 0.0846 - val_loss: 162.3229 - val_acc: 0.0385\n",
      "Epoch 44/100\n",
      "390/390 [==============================] - 0s 185us/step - loss: 87.1552 - acc: 0.0821 - val_loss: 162.0301 - val_acc: 0.0385\n",
      "Epoch 45/100\n",
      "390/390 [==============================] - 0s 160us/step - loss: 87.3572 - acc: 0.0769 - val_loss: 161.5337 - val_acc: 0.0385\n",
      "Epoch 46/100\n",
      "390/390 [==============================] - 0s 161us/step - loss: 87.2992 - acc: 0.0795 - val_loss: 161.3913 - val_acc: 0.0385\n",
      "Epoch 47/100\n",
      "390/390 [==============================] - 0s 135us/step - loss: 87.1617 - acc: 0.0795 - val_loss: 161.7961 - val_acc: 0.0462\n",
      "Epoch 48/100\n",
      "390/390 [==============================] - 0s 130us/step - loss: 87.3619 - acc: 0.0795 - val_loss: 161.0557 - val_acc: 0.0385\n",
      "Epoch 49/100\n",
      "390/390 [==============================] - 0s 124us/step - loss: 87.3260 - acc: 0.0769 - val_loss: 161.7030 - val_acc: 0.0462\n",
      "Epoch 50/100\n",
      "390/390 [==============================] - 0s 132us/step - loss: 87.4331 - acc: 0.0769 - val_loss: 161.1683 - val_acc: 0.0385\n",
      "Epoch 51/100\n",
      "390/390 [==============================] - 0s 135us/step - loss: 87.1135 - acc: 0.0795 - val_loss: 161.4273 - val_acc: 0.0462\n",
      "Epoch 52/100\n",
      "390/390 [==============================] - 0s 117us/step - loss: 87.0770 - acc: 0.0795 - val_loss: 161.6349 - val_acc: 0.0385\n",
      "Epoch 53/100\n",
      "390/390 [==============================] - 0s 117us/step - loss: 87.1979 - acc: 0.0821 - val_loss: 161.2578 - val_acc: 0.0462\n",
      "Epoch 54/100\n",
      "390/390 [==============================] - 0s 125us/step - loss: 87.1400 - acc: 0.0769 - val_loss: 161.2771 - val_acc: 0.0385\n",
      "Epoch 55/100\n",
      "390/390 [==============================] - 0s 151us/step - loss: 87.1495 - acc: 0.0795 - val_loss: 160.9145 - val_acc: 0.0385\n",
      "Epoch 56/100\n",
      "390/390 [==============================] - 0s 146us/step - loss: 87.1449 - acc: 0.0795 - val_loss: 160.8654 - val_acc: 0.0385\n",
      "Epoch 57/100\n",
      "390/390 [==============================] - 0s 131us/step - loss: 87.2046 - acc: 0.0744 - val_loss: 160.2114 - val_acc: 0.0308\n",
      "Epoch 58/100\n",
      "390/390 [==============================] - 0s 133us/step - loss: 87.2671 - acc: 0.0821 - val_loss: 161.0228 - val_acc: 0.0385\n",
      "Epoch 59/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "390/390 [==============================] - 0s 136us/step - loss: 87.1304 - acc: 0.0769 - val_loss: 160.7399 - val_acc: 0.0308\n",
      "Epoch 60/100\n",
      "390/390 [==============================] - 0s 130us/step - loss: 87.2043 - acc: 0.0795 - val_loss: 160.2612 - val_acc: 0.0385\n",
      "Epoch 61/100\n",
      "390/390 [==============================] - 0s 117us/step - loss: 87.0946 - acc: 0.0744 - val_loss: 160.0098 - val_acc: 0.0308\n",
      "Epoch 62/100\n",
      "390/390 [==============================] - 0s 114us/step - loss: 87.2990 - acc: 0.0821 - val_loss: 160.1672 - val_acc: 0.0308\n",
      "Epoch 63/100\n",
      "390/390 [==============================] - 0s 113us/step - loss: 87.2743 - acc: 0.0821 - val_loss: 159.9530 - val_acc: 0.0308\n",
      "Epoch 64/100\n",
      "390/390 [==============================] - 0s 114us/step - loss: 87.3527 - acc: 0.0769 - val_loss: 160.6970 - val_acc: 0.0308\n",
      "Epoch 65/100\n",
      "390/390 [==============================] - 0s 124us/step - loss: 87.2199 - acc: 0.0769 - val_loss: 159.7548 - val_acc: 0.0385\n",
      "Epoch 66/100\n",
      "390/390 [==============================] - 0s 131us/step - loss: 87.1167 - acc: 0.0744 - val_loss: 160.8728 - val_acc: 0.0385\n",
      "Epoch 67/100\n",
      "390/390 [==============================] - 0s 141us/step - loss: 87.2202 - acc: 0.0821 - val_loss: 160.5090 - val_acc: 0.0308\n",
      "Epoch 68/100\n",
      "390/390 [==============================] - 0s 137us/step - loss: 87.3020 - acc: 0.0744 - val_loss: 159.2375 - val_acc: 0.0385\n",
      "Epoch 69/100\n",
      "390/390 [==============================] - 0s 134us/step - loss: 87.2505 - acc: 0.0795 - val_loss: 159.9900 - val_acc: 0.0308\n",
      "Epoch 70/100\n",
      "390/390 [==============================] - 0s 128us/step - loss: 87.3738 - acc: 0.0821 - val_loss: 160.7302 - val_acc: 0.0308\n",
      "Epoch 71/100\n",
      "390/390 [==============================] - 0s 137us/step - loss: 87.0909 - acc: 0.0795 - val_loss: 160.7668 - val_acc: 0.0385\n",
      "Epoch 72/100\n",
      "390/390 [==============================] - 0s 145us/step - loss: 87.2777 - acc: 0.0769 - val_loss: 159.9358 - val_acc: 0.0231\n",
      "Epoch 73/100\n",
      "390/390 [==============================] - 0s 157us/step - loss: 87.1706 - acc: 0.0744 - val_loss: 159.2799 - val_acc: 0.0385\n",
      "Epoch 74/100\n",
      "390/390 [==============================] - 0s 171us/step - loss: 87.1257 - acc: 0.0769 - val_loss: 159.7679 - val_acc: 0.0308\n",
      "Epoch 75/100\n",
      "390/390 [==============================] - 0s 159us/step - loss: 87.1810 - acc: 0.0744 - val_loss: 160.4323 - val_acc: 0.0385\n",
      "Epoch 76/100\n",
      "390/390 [==============================] - 0s 145us/step - loss: 87.1790 - acc: 0.0744 - val_loss: 159.4621 - val_acc: 0.0385\n",
      "Epoch 77/100\n",
      "390/390 [==============================] - 0s 119us/step - loss: 87.1014 - acc: 0.0769 - val_loss: 159.7503 - val_acc: 0.0231\n",
      "Epoch 78/100\n",
      "390/390 [==============================] - 0s 115us/step - loss: 87.2012 - acc: 0.0795 - val_loss: 160.6862 - val_acc: 0.0385\n",
      "Epoch 79/100\n",
      "390/390 [==============================] - 0s 115us/step - loss: 87.0558 - acc: 0.0795 - val_loss: 159.5674 - val_acc: 0.0231\n",
      "Epoch 80/100\n",
      "390/390 [==============================] - 0s 119us/step - loss: 87.1723 - acc: 0.0769 - val_loss: 159.5081 - val_acc: 0.0308\n",
      "Epoch 81/100\n",
      "390/390 [==============================] - 0s 132us/step - loss: 87.3188 - acc: 0.0846 - val_loss: 161.2873 - val_acc: 0.0385\n",
      "Epoch 82/100\n",
      "390/390 [==============================] - 0s 129us/step - loss: 87.1772 - acc: 0.0769 - val_loss: 159.3849 - val_acc: 0.0385\n",
      "Epoch 83/100\n",
      "390/390 [==============================] - 0s 155us/step - loss: 87.1289 - acc: 0.0769 - val_loss: 159.8098 - val_acc: 0.0231\n",
      "Epoch 84/100\n",
      "390/390 [==============================] - 0s 158us/step - loss: 87.0900 - acc: 0.0795 - val_loss: 160.2618 - val_acc: 0.0308\n",
      "Epoch 85/100\n",
      "390/390 [==============================] - 0s 143us/step - loss: 87.1590 - acc: 0.0744 - val_loss: 159.7214 - val_acc: 0.0231\n",
      "Epoch 86/100\n",
      "390/390 [==============================] - 0s 134us/step - loss: 87.0901 - acc: 0.0769 - val_loss: 160.0238 - val_acc: 0.0231\n",
      "Epoch 87/100\n",
      "390/390 [==============================] - 0s 128us/step - loss: 87.1683 - acc: 0.0769 - val_loss: 160.1552 - val_acc: 0.0231\n",
      "Epoch 88/100\n",
      "390/390 [==============================] - 0s 140us/step - loss: 87.1468 - acc: 0.0795 - val_loss: 160.3657 - val_acc: 0.0308\n",
      "Epoch 89/100\n",
      "390/390 [==============================] - 0s 136us/step - loss: 87.1375 - acc: 0.0744 - val_loss: 159.8104 - val_acc: 0.0231\n",
      "Epoch 90/100\n",
      "390/390 [==============================] - 0s 168us/step - loss: 87.1583 - acc: 0.0769 - val_loss: 159.6742 - val_acc: 0.0231\n",
      "Epoch 91/100\n",
      "390/390 [==============================] - 0s 137us/step - loss: 87.2583 - acc: 0.0769 - val_loss: 159.5996 - val_acc: 0.0231\n",
      "Epoch 92/100\n",
      "390/390 [==============================] - 0s 144us/step - loss: 87.1129 - acc: 0.0769 - val_loss: 159.6953 - val_acc: 0.0231\n",
      "Epoch 93/100\n",
      "390/390 [==============================] - 0s 174us/step - loss: 87.1669 - acc: 0.0718 - val_loss: 160.3096 - val_acc: 0.0308\n",
      "Epoch 94/100\n",
      "390/390 [==============================] - 0s 135us/step - loss: 87.1220 - acc: 0.0795 - val_loss: 160.0048 - val_acc: 0.0231\n",
      "Epoch 95/100\n",
      "390/390 [==============================] - 0s 133us/step - loss: 87.2442 - acc: 0.0744 - val_loss: 160.0825 - val_acc: 0.0308\n",
      "Epoch 96/100\n",
      "390/390 [==============================] - 0s 133us/step - loss: 87.0593 - acc: 0.0769 - val_loss: 159.6240 - val_acc: 0.0231\n",
      "Epoch 97/100\n",
      "390/390 [==============================] - 0s 145us/step - loss: 87.0905 - acc: 0.0769 - val_loss: 159.2942 - val_acc: 0.0308\n",
      "Epoch 98/100\n",
      "390/390 [==============================] - 0s 124us/step - loss: 87.1611 - acc: 0.0744 - val_loss: 159.5042 - val_acc: 0.0308\n",
      "Epoch 99/100\n",
      "390/390 [==============================] - 0s 126us/step - loss: 87.1888 - acc: 0.0795 - val_loss: 159.7050 - val_acc: 0.0231\n",
      "Epoch 100/100\n",
      "390/390 [==============================] - 0s 119us/step - loss: 87.3349 - acc: 0.0821 - val_loss: 160.7498 - val_acc: 0.0385\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IQ : MAE : 7.746153846153846\n"
     ]
    }
   ],
   "source": [
    "iq_model = Sequential()\n",
    "iq_model.add(Dense(8, input_dim=iq_train_X.shape[1], kernel_initializer='normal'))\n",
    "iq_model.add(Dense(4, kernel_initializer='normal'))\n",
    "iq_model.add(Dense(2, kernel_initializer='normal'))\n",
    "iq_model.add(Dense(output_dim=1, kernel_initializer='normal', activation='relu'))\n",
    "\n",
    "iq_model.compile(loss='mean_squared_error', optimizer='adam', metrics=['accuracy'])\n",
    "iq_model.summary()\n",
    "\n",
    "hist = iq_model.fit(iq_train_X, iq_train_y.values,\n",
    "          batch_size=10,\n",
    "          epochs=100,\n",
    "          validation_data=(iq_test_X, iq_test_y.values)\n",
    "            )\n",
    "plt.plot(hist.history['loss'], label='train')\n",
    "plt.plot(hist.history['val_loss'], label='test')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "iq_pred = iq_model.predict(iq_test_X).astype(int)\n",
    "print(\"IQ : MAE : \" + str(mean_absolute_error(iq_test_y, iq_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "sj_pred_X, iq_pred_X, c, d = preprocess_data(test_feature_filename)\n",
    "\n",
    "sj_pred_submit = sj_model.predict(sj_pred_X)\n",
    "iq_pred_submit = iq_model.predict(iq_pred_X)\n",
    "\n",
    "sj_predictions = np.array([int(round(x[0])) for x in sj_pred_submit])\n",
    "iq_predictions = np.array([int(round(x[0])) for x in iq_pred_submit])\n",
    "\n",
    "# sj_predictions.shape\n",
    "# iq_predictions.shape\n",
    "\n",
    "\n",
    "submission = pd.read_csv('submission_format.csv', index_col=[0, 1, 2])\n",
    "\n",
    "submission.total_cases = np.concatenate([sj_predictions, iq_predictions])\n",
    "\n",
    "submission.to_csv(\"submission_new_nn.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEVCAYAAADtmeJyAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAIABJREFUeJzt3XeYG+W1wOHf2e7eMcbGBTAYm45jaiChGkIwCSkQCDUhcCH3JnBzMSGJCYQEQgKEEkoCCYRuSMBUU2zTDMZrbNyN18Zljcu6160694/5RjurlXa1a600K533efbZ0cxIczSS5sxX5htRVYwxxuSuvEwHYIwxJrMsERhjTI6zRGCMMTnOEoExxuQ4SwTGGJPjLBEYY0yOs0RgUkpELhGRDwKPt4vIPmnY7hQR+VFbb8e0nIgsE5FTMh2HScwSQZLcl3mXiGwTkc0iMlVErhSRdrUPRWSwiKg7QG9372tsW21PVTur6tIkYypoqzhEZH8RGS8i60Vki4jMFpFrRSS/rbYZBi4xq4h8vwXPSWtSFZFRIvKa+11tFJFPROTSdG3fWCJoqW+qahdgEHAbcD3wSGZDarXuqtoZOB/4jYiMjl2hLQ/M6SQi+wLTgJXAwaraDfguMBLoksnY0uBiYCNwUaYDiUdEjgEmAe8C+wG9gKuAMzIZV85RVftL4g9YBpwSM28UEAEOco+LgT8BK4C1wINAB7fsa0A5cB2wDlgNXBp4rV7Ay8BWYDrwO+ADt2wwoEBBYP0pwI8Cjy8DFgCbgInAoATvI95rTQf+100rcDWwGPjCzRsGvIV3QFkEfC8m7gku7k+AW/y4A6+3n5vuAPwZWA5sAT5w81a49ba7v2Oae0/AqcBC9zr34R1IfpTgPT8BvNrM5zseWONe7z1gRGDZmcB8YBuwyt9XbtlZwCxgMzAVOCSw7Hq3/ja3306Os92j3HbzA/O+BcwOfMdK3f5dC9zZgu/sILzv57lALbBnzPIxLvatwBJgNHArUAdUus/ivua+f8C+eAfzDcB64Em8E42Ev53Asg+A+5t4Dz2AV4AK9z14BRgQWH4JsNTt4y+AC5r7TQAC3IX3O9wKzMH9hnP1L+MBtJe/RF9mvIPYVW76LryDYk+8M82XgT+4ZV9zP8abgUJ3cNkJ9HDLn3F/HYHheGevSSUC94MuAw4ECoBfAVMTvI/oa7kfxHEujpPdcsU76PfEO0h3crFc6p5zuPuxDw/E/Zxb7yC8A1+iRHC/i7s/kA8ci5c8472/hO8J6O1++N9x+/Lnbt8mSgRrCCTdBOtc5j6zYuBuYFZg2Wrgq266B3CEmz7cHUyOcu/nYvc9KQYOcPttr8B+3zfBtpcApwYejwfGuumPgB+66c7A0S34zv4a+MRNzwGuCywbhZf0TsWrGegPDIv9biX5/dvPvU4x0Acvkd6dxG+nI17S+XoT76EXXiLr6D6f8cCLblknvAP5Ae5xP1wCb+b7czowA+iO9xs4EOiX6WNMJv8yHkB7+Wviy/wxcKP7Qu0I/tiBY6g/q/4asCvmx7QOONodRGr8L7RblnSJAHgduDywLA/v4D4oTrz+a23GO1NaAPx3YLkCJwUefx94P+Y1HgLGBeIeFlj2e+IkAhfTLuDQJmIKvr+E7wmvmuPjwDLBK20lSgQ1wOgWfNbdXTzd3OMVwE+ArjHrPQDcEjNvEXCie8/rgFOAwma29zvgUTfdxX2PBrnH7wG/BXq34ju7GPiZm74B+CzmM7wrwfOi361kvn9xnn8OMDOJ305/97rDknk/7jmHAZvcdCf3PT4XV/JO8vtzEvA53m8vr6X7NRv/rI1g9/XHqzLpg3fWMsM1em0G3nDzfRtUtTbweCfeWV4fvLOWlYFlwenmDAL+EtjuRryDY/8mntNbVXuo6oGqek/MsuC2BwFH+a/tXv8CYM8EcS9PtD2gBO/sd3ff017Bbar3S29qf23AO1uMS0TyReQ2EVkiIlvxDlx+zOAdaM4ElovIu65e24/xuph9szdeKaAM+BlwE7BORJ4Rkb0ShPAU8G0RKQa+DXyqqv5+vBzYH1goItNF5Kwm3mfwPR0HDMErsfnbOFhEDnOP9yb5z6K5bfV172+V239PUL/vmrIJr+qqqc+mo4g8JCLL3Wu/B3QXkXxV3YF3onIlsFpEXhWRYe6pCb8/qjoJr8rrfrzP5mER6dq6d58dLBHsBhH5Ct6B6QO86pJdeEXT7u6vm3oNss2pwKvaGBCYt3dgeof73zEwb8/A9ErgJ4HtdlfVDqo6taXvydGY13435rU7q+pVgbiDsQ5M8Jrr8eqd921me8HtJnpPq4PbFBGJiSHW23gH80R+gFeVcArQDe8MGLwDB6o6XVXHAHsAL+JVhfkx3hoTY0dVfdo97ylVPR7voKTA7fE2rqrz8RLoGS6WpwLLFqvq+W7btwPPi0inJt6L72IX/ywRWYPXWO7P92OP91lA48+jue/f791zDlbVrsCFbttNUtWdeFVfTX021+FVsx3lXvsEN9//bCaq6ql4yWQh8De3vMnfhKreo6pH4lXD7g/8orl4s5klglYQka7uzOwZ4AlVnaOqEbwv4V0isodbr7+InN7c66lqHfBv4CZ3BjSMQC8PVa3Aq3u/0J29XkbDH/GDwA0iMsJtt5uIfDc175ZXgP1F5IciUuj+viIiB8aJezj1B5rY9xgBHgXuFJG93Ps4xp0FV+CdGQavN2jqPb0KjBCRb7ueTf9NwwNTrHHAsSJyh4js6V5vPxF5QkS641XHVOGVHDriHdhw6xWJyAUi0k1Va/DqpCNu8d+AK0XkKPF0EpFviEgXETlARE5y768S7yQhQmJPAf+Dd6AbH9j+hSLSx+2/zW52U6+DiJQA3wOuwKtK8f9+CvzA7bNHgEtF5GQRyXPfVf9sei2BzyKJ718XvIblLSLSn5YdVP8PuEREfiEivVz8h4qIX5LpgrfvNotIT7zP0n+ffUVkjEuMVS4Gf98k/P647+9RIlKIl+QqaWafZr1M1021lz+86oJdeI2UW/DOZK6mYW+PEryDyFK8A0a0/h3XayjOa57ipvvgHeD8XkO3A+8E1j0Dr1fEZryeNw16yQA/xGsQ3Ip3NvRogvcxmJj63pjl0cbdwLwDXGwVeAfLScBhgbhfIfleQ3fjHVT83jl+r6qb3etvxjWINvWe8Hq4fE4SvYYC72G8i38L8Ble1U0+XvXcS+6zXY6XhP22jSK8Kr5Ngc/m+Jg4pru4V7ttdAEOcftjG161xCu4huME8Q3EOxi9GjP/Cby2hu3APOCcwLLtuEbsmOec52IpjJnfwb3/s9zjbwGzXYxlwOlu/jFu324C7mnu+weMwGt83Y7XC+k6At91mug15JaPwqvT3+L21TTgIrdsL7z2iO0upp9Q39mhn4tji4trCq4TQ1PfH+Bk9763U9/LqXOmjzGZ/BO3Y0zIiMjteN394p5hG2NMqljVUEiIyDAROcRVMYzCayT8T6bjMsZkv6y4cjRLdAGexisKr8Urfr+U0YiMMTnBqoaMMSbHWdWQMcbkOEsExhiT4ywRGGNMjrNEYIwxOc4SgTHG5DhLBMYYk+MsERhjTI6zRGCMMTnOEoExxuQ4SwTGGJPjLBEYY0yOs0RgjDE5zhKBMcbkOEsExhiT40J3P4LevXvr4MGDMx2GMca0KzNmzFivqn1a89zQJYLBgwdTWlqa6TCMMaZdEZHlrX2uVQ0ZY0yOs0RgjDE5zhJBiDw1bQXffXBqpsMwxuSY0LUR5LJf/mdOpkMwxuQgKxEYY0yOs0RgjDE5zhJBCEUimukQjDE5xBJBCNVEIpkOwRiTQywRhFCdlQiMMWlkiSCEai0RGGPSyBJBCNXVWSIwxqRPqxKBiOSLyEwRecU9HiIi00SkTESeFZEiN7/YPS5zywenLvTsZW0Exph0am2J4H+ABYHHtwN3qep+wCbgcjf/cmCTm3+XW88046JHPsl0CMaYHNLiRCAiA4BvAH93jwU4CXjerfIYcI6bHuMe45af7NY3TVi4ZlumQzDG5JDWlAjuBv4P8OsvegGbVbXWPS4H+rvp/sBKALd8i1vfGGNMSLQoEYjIWcA6VZ2RyiBE5AoRKRWR0oqKilS+tDHGmGa0tERwHHC2iCwDnsGrEvoL0F1E/AHsBgCr3PQqYG8At7wbsCH2RVX1YVUdqaoj+/Rp1Q12jDHGtFKLEoGq3qCqA1R1MHAeMElVLwAmA99xq10MvOSmJ7jHuOWTVNX6RhpjTIik6jqC64FrRaQMrw3gETf/EaCXm38tMDZF28s6lh+NMZnS6vsRqOoUYIqbXgqMirNOJfDd1m4jl9iwEsaYTLEri0OizkoExpgMsUQQErEXE1sJwRiTLpYIQiK2RPDF+u0ZisQYk2ssEYREbAlgW2VtgjWNMSa1LBGEROxdyWwoamNMulgiCInYqqFaG4raGJMmlghConGJwIaiNsakhyWCkGhUIghx1dDWyhq7AM6YLGKJICT8xuL8PG+U7rDepWzlxp0cctObPDZ1WaZDMcakiCWCkPBrgi49djAQ3qqh5Rt2AvDm/LUZjsQYkyqWCELCrxoqLvQ+krBWDfm3FbKaIWOyhyWCkPCrhory84Hw9hryby+nhDM+Y0zLWSIIiUg7KRFgJQJjso4lgpCoLxG4RFAXzjYCcZnA8oAx2cMSQUhU13oH/o5FrmoopCUCqa8bMsZkCUsEIVFZUwdA5xLvFhFhLRH4rI3AmOxhiSAkKl2JoFOxSwQhLRH4V0BbG4Ex2cMSQUj4JYIuLhGE9X4EfoIKZ3TGmNawRBASfiIIe4mgLloiCGd8xpiWs0QQElU1XtVQZz8RhPQ6AisRGJN9LBGERI0bUqK4II88Ce8QE3UuLisQGJM9LBGERHDQuYK8vNBWDVmJwJjsY4kgJPyqoIK8PPLzJLTdR6ON2FYkMCZrWCIICf8Am5cHBfkS3hJBnZUIjMk2lghCwj/wF+TlUZAnoW0srrPrCIzJOpYIQsJvhM3PEwry20MbQTjjM8a0nCWCkKgvEQgFeRJNDGFjvYaMyT6WCEKiLqKIQF6eeG0EIa0aqrWqIWOyjiWCkKiLKAXufsVh7j5aZ91Hjck6lghCoi6i0RvXF+RJaC8oq7UhJozJOi1KBCKyt4hMFpH5IjJPRP7Hze8pIm+JyGL3v4ebLyJyj4iUichsETmiLd5ENqiNKAV53seR3w56DVWH9DoHY0zLtbREUAtcp6rDgaOBq0VkODAWeEdVhwLvuMcAZwBD3d8VwAMpiToLNSgRtIPrCHZV12U4EmNMqrQoEajqalX91E1vAxYA/YExwGNutceAc9z0GOBx9XwMdBeRfimJPMvURiLtpI3AKwnsqKrNcCTGmFRpdRuBiAwGDgemAX1VdbVbtAbo66b7AysDTyt380yMmlqlID/QRhDSqhc/QW2vqrV2AmOyRKsSgYh0Bl4AfqaqW4PL1Ds6tOgIISJXiEipiJRWVFS0JqR2b0d1LZ2KvCGow1w15LcRRBR21Vj1kDHZoMWJQEQK8ZLAk6r6bzd7rV/l4/6vc/NXAXsHnj7AzWtAVR9W1ZGqOrJPnz4tDSkr7Kquo2Oxd+P6gry80N+hDGB7pVUPGZMNWtprSIBHgAWqemdg0QTgYjd9MfBSYP5FrvfQ0cCWQBWSCdhRXUvHYIkgpFVD1bX1cW2zdgJjskJBC9c/DvghMEdEZrl5vwRuA54TkcuB5cD33LLXgDOBMmAncOluR5yldlbX0bNTEeBfRxDOEkFNIEFZg7Ex2aFFiUBVPwAkweKT46yvwNWtiCvnVNdGKMoP/3UEwRJBWJNVLqmpi1BVG4ne4tSY1rAri2OMuvVt/vzmorRvtzaiFLpE4I0+Gs6qoapAiSCsySqXXPXEDA4aNzHTYZh2zhJBjHXbqrh3Ulnat9t4iIlwHmRrGpQIwpmscsnbC9Y1v5IxzbBEEBI1dTEXlIX0bDs4tERYezblIvsszO6wRBAQyeCPqS5Sf0HZvC+3sGrzLmat3JyxeBKprq1PWGFNVrmoqtau6TCtZ4kgIJMDqdVGlHw36NzCNdsAeHdR+C6uq66N0LHIu94hrNVXuaiyxqrpTOtZInDWbq3k2NsmZWz7tYGqIV9+CD+dndV1dO1QCBDau6jlokq7ytvshhAeajLjqN+/w8Yd1Rnbfm2gsdjnXb8XLjura+la4iWCGqsaSkpVbR2/GP8Z5Zt2ttk2LBGY3WGJICTqIkphfsMDf14IE8GO6jq6dvD6rFsDZXJmrtjM+BnlXPfcZyl/bf/cwaqGzO6wRBAStXX1bQS+vJDlgYptVVRsq2KXO+j87NlZbMpgKaq9WLjaG5dxQxvsqwJXf1hpjcVmN1giCIng/Qh8YSsRrNq8C4D9+nSOznvi4+WZCqfduOnl+QBE2mDY7kL3nbGqIbM7LBHEOGH/Poik9568kYgSUaLdR8PKvyvZCfv3js4rLLCvULJiE31KXtOVCKqysGrosanLWLB6a/Mrmt1mv2LHH/DtiIHdUYWq2vT9sPxuq/4QE8Xu4Kotu61DSrw+ZzXfeWBq3EToVz8Ex7UpDGPXppD51uHevZj871iqbNlVw5ZdNUB2lgjGTZjHGX95P9Nh5AT7FTsH9O3CVwb3oLvrGlm2bnvatu2P4tnJ9c9/6sdHAdC5uDBtMfiuevJTSpdvinuNQGV140RQZCWCZvkjtqb6Ps+fLt8Unc62NgK7+1162a/YqamLUJifR0d3kDvr3g/Stu2d7gDRyW17UK9OQGb66Uu0F0rjA0u0RFASSAQhr84KAz8RpLpnT/BzyLZeQ3axYnpZInBq3Oif/lWz6bTdlQj8M+1C13soEz8Gv4E6XtXYrmpvXpdASaUgz75CzfGvt0j1WXtwSPBsqxqqCemNmbKV/YqdnVW1jRJBuoqnftWQXxrJz8/cWD55TZUIahqXCOpUmVq23n64TfAP2Kk+WN/yyvzodLaVCOxixfSyRIB35efiddsZtmcXOhTWH+TKN+1Ky/YXrfXGFurs7llc4urdM3FzeGmqRODiCSbLP7y2gB/8fRr3vLM4PQG2Qys2elcUp/pg7Y9J5b22lQhM61kioP4m7H26FDc4yPk/4LZ243/mAvVtBAX5eXQqymer6xGSTn6JIF53xMqaOkTqezUBbNrpxbikIn2N6+1JJKLR79Gu6ro2K2VmW2OxJYL0skQAXDfeu/S/U3FBg0QQ7yxLVbn3ncWc/OcpKR+bqFNRfWmkS0khWyvTnwjE3Ym0sraOWSs386+PlkWXVdbU0aEwP+4YSK/NWcPMFZsazW9rL81axauzV6d9u8naEkjm1XURNu9MzWcam1Cy7ToCG+I8vbI+Eby/uIJv3PN+g4a1WFPccM9+1YwvXlF+3pdb+fNbn7OkYgevz03tAahDIAl17VDA1l3pvzm8XyLYVlnLOfd/yK9fmhc96OyqqaOkMHFj+utz16QjxChV5X+emcXVT30a2qEu/GElTh/RF4A1WytT8roLVm9r8Djbqob8a2tCdnF91sr6RPCL8bOZ9+VW1m2L/wMMnll161DEkN6dOGRANwAefm9Jo/V/+/K86HRNCi86O6h/V3p3Lo4+7pqhEoHfU+niRz+JztvmGrM37ayJXmcRTzqHxPh87bYGXXzXJvh8M80vNe7doyNQ31V4d23a6b3uKQfuwcCeHbMuEfglgrANsxLP3FVbqG3nVVlZnwj8usZEVbMzAhflHLp3Nwry83j4hyMB+Kx8S3R8Hd/arVXR6Ztens/Ln325W/H5d0U7aVjfBvO7lBSwrTL9JYJ4jcTTv9gIwPptVQ2SVaxEQyg88fFyDvjV6/zv+NSNvvnjx0uZ92X98AM7qsJ5INy4w/u+7NW9AwBVKTpg+3cku+akoZQU5mVhryHv/eRnOBFsr6ptcpiLsnXbOeveD7jjzUVpjCr1sj4R+Ae2Rz74Iu5y/8D+x3MPoaOroy8prN8t33vwowbrxw4V/dOnZ+5WfPF64gB07VDYoH45HRI1ZK7b5u2jNVsr2aNr4kSQaFC1X704l6raCM/PKN/9IJ3YM2C/C27YbNzhfYZ+Irg7Rb2r/KrO4oI8SgrzM9LDrC2FpWroisdLOeMv7yccct0v8ZUuS3/7WCplfSLwL9b659RlTfbYOGxg9+i0f+MVoEGJQFVZmeIupRNciaJPzJl2n87FVGyrShizqjJl0bqU9kKZuyr+mc8DU5aweWc1yzfsZLC76vmYfXpx9qF7cfExg5h03YkA/HVK46q0tqq796++HtTLr3IJayLwSwQlAHzyxcbod3J3VAUTQUE+c1dt2e3XDJOwVA1NXbIBSHxPaP9mUsGahfYoqxNBbBe0iu1VjdaprvM+4KLA4Gl5ecI3Du7XaN2q2gjVtRH+97T9WxTHuJfm8s0EQ1bc8O85AOzft0uD+Xt2K2FXTV3CUsH4GeVc8o/pKTvLLlu3jW/eVx9jz05FDNvTi2nFxp2cc/+HQP3YQk9fcTT3nH84vx1zEPsEhqWOdd/ksgaPUzXeTl1EOXbfXvzrMm9cprBWDW3YUU2novwGg/MtWrOtiWckx0+wRQV5bK+qZcOO6qwanydaNRSSm3Ik6pU1aeHaNEfSNrI6EQy98fUGjxev3d7ozNH/gIsLG+6KeCciOwODrgUHW4s0MRREJKI89tFy5qzawk0T5nHHxIV85M4ygvbdo1ODx/26eVUJq7c0bgT954dfcP0LswFYviE11zqs315/5v6rbxzI1LEn8cbPTojO86/0/PYR/eM+/9wjBgA06FJbWxdpVCV34G/eaDaWSER5ZfaXCYvjNXURZizfRM9ORXR0Pb3eWbiWLzfvfmlty64aBo99lf1++Rpvztv9XlAbd1TTs3MRe3Ytic4rXbZxt1/Xv8dBcUE+3zjEO2nJVPXQJ19sZPWW1JaU17reVS0pEHy5eRf3vrO4TRJionaC+yc3LgW3R1mdCGJd8PdpjW4X6NdFFsUMpxzvTPxv7y8FvKEggo1YI299mzcSdJ2cGjjo/3PqMu6fvITz//Yx67dXRfvdnzRsj2j7hG/Pbt6BY02cRHDTy/Ojjd/3TS5rti3hxZmruPrJT6mti/DG3NVx1w82En9lcM9G3URXbd7FsD27MMD1fok1pLc3/9J/1Pc22rizddVCL3xazjVPzUx405vxpV4p6MvNu6LXXrw2Zw1XPflpq7YXdNa93rDHtRHlin/NaNRZoKU27qimZ6dienQqYtlt36BzcUGzXUiXVmxnxvLEySJYCiwpzKOrG/Ij3nelrakq33voI07607spfd1r3e+0JVVDVz/1abRrd6r94O/Tml1HVbnqiRm8s6D9lRKyNhEEbxT+yzOHRaf9awZ8fokgdjjl80cNjE4PvfE1bpowjwdcHXh1bYTHLx9F787e+PIbd1Rz3+TGjYAV26oSDr0wu3wz5//tYwCO2693o+V+nXK8EkGsu976PO78ypo63l9cwc+encWrc1az342vc+UTn3Lob99sdIYTbGzt36NDdPry44dEp088oE/CGLa7qpnPyuvrql9r5YVefhXeuAnz4p5p+g3F4745okHD/mcrN7dqe773F1ewcmPD7a1oosRVUxdptppn7dZKenasb3Pao0txs0OXnPTndzn3gY8SLvd7X52wfx+6lBRGG/N//Hhpk6+bav/+tJwhN7wGtF1ppCUlAr+6rKkk2hKxHRDiXUA6dI/6atGVG3fx+tw1XP5Yej+HVMjKRKCqHH/75Ojjrx2wR3R6V00d735ewZRF69hZXcsOV1UUmwjOPLgfE13VSE2d8s+py6LLzj5sL74yuCfTfnlKtLdPcIz+hWu28uLMVXzl1rf5JEE1wPUvzIl2+fv+V/ZutLxP52LyhEYHwr+7UknQP6cu47bXF/Lx0oZVTjf+Zy4/fOSTRusDjW744V/x+thloxp0ER17Rn0SverEfeO+FsA3D61vU/Gr3/zqC4AXrjqGX5x+AABPTmv69pY1tfVF+8v+2fBHVRdR3l6wlqL8PA7u363RVc6tPYOfsXxjg33lV4E9M31Fox5KtXURKmvq+MNrCzn97vcSbnPmik18vnZ7g+q7pet38Nb8tUk1blfXRqipiyRsV7n/B4cDRD+vVHdk2FFVy5PTlkerWmat3BydVtWUdgcOClbtJHutzuotu1jm9vP1L8xJSRzB3zw0vIbIF/yt+GOGtUdZmQjeX7w+Ov3tI/o3yNrgXSx1yT+mM/w3E7n77cUM6d2J4oLGV8wesGcX7vzeodHHo4b0ZPZNp0V7FeXnCfNvHs2B/bry8dKNPP7RMu6btJjRd7/Pz56d1eC1LjpmEAD9XTfCCncW97UD+jRIIr6C/DwiCvdOKqNs3TaqayNsq6zhd68uAOCrQ3tHG3MBHnx3Cec9/HGD13j38/rSzw+PHtRoG78Y/1m0N8SiNVvpVJTPV2NKJ4X5ecy+6TReuOpYundMfIetEXt14yxXVz38NxP5+p+mRN8rwD69O0d7Rt34n7lx20nAO/jc9XZ9CWfB6q0MHvsqP3tmJpGI8v2HPmLqkg1U10XIcw2JXx1aH/Nxt01KGGNT/P0K8MmNJ3Pn9w4D4KVZXzLs1280aK+46NFPGPbrN3j0wy+i21y/vYpPV2xqcBb5kUvM3To2vgjvkkenN0rcQIMqxv1/9TpDb3ydA3/zBqNufZvBY19tMJxGF/c9vND/bDW13Wh/+/I8bvzPXO5663NueWU+59z/If9y1XUvzlpFbBNOKurm6yIaLWUA7HBJUFXZ0sTwHLEl/UTfr5b4PObA/vnahuNpRSLaYIytlYGxyRJdwOqrro1w/+Qybvj37FB0fU5LIhCR0SKySETKRGRsW29v085gw+dwRIRJ150YvQNYrK8M7pHwtb59xADevvYEvnnoXtz5vUMbdC31+QfT37w0jz+92bia5sELj+TmMQfx2bjT+OD6rzO8X9fosmQumDnlzvc47vZJHHzTm9F5Yw7rz33ujDDI/wG8MvtL1rsqlm8d3p9bzjmIz35zGn+94IjouuNnlHPqne8xeOyrPPbRchSiB9egriWFHDko8T7yBff7F+t3RM/qCHcLAAAZsElEQVSUX7jqWHp0KqJf9/oG0w/L1jd6PsCb8+O3tbw460uGj3uD0jjd9P703UM5Yf/6aqulCQbAm75sI5MXruN3r8xnzH0fsGLDTpZWbOfLzbuYucKrVjrrkH7s0aWk0XOfn7GSypo6xpeubNDu4xv5u7f59l+n8oO/T4t2JfQPXI9fNiq63h/PPQSAT5Zt5OZAiWn99iqe/mQFVz4xI27sfvXP1U957SD3nl//2efnCUfv05Pquggjxk1MWc8sfxiLeyaVRRv9f/PSPGrqIvz82calgU2tHEepti7CfZMW8/b8tXyxvuFn171jIWXrtjPkhtc49OY3eSzmLB3gudKVPPhuw0Zbv9o11pvz1vD8jHIu/ccnTFq4lqraOqpq6xpdxb96y65GHTFKYjqULFizlXXbqqI9DG8ODAv+weL1TSbGifPWcMfERTz9yUpGjJuYcL10kbbuciYi+cDnwKlAOTAdOF9V58dbf+TIkVpa2ro6NlXliWkr+PWL3mieY88YxpWB6ozaugg7qut4bvpKbn2t/gzwzZ+f0Kj7Zku8OHNVoxKA7/QRfXnIXansW7+9ipG/exuACdccxyEDusd7KnNXbYl7p7Q7vnMI3zlyACLCll01HPrbNxssv/f8w7l30uLoGUzZrWdEb3IO8NC7S/jD6wvjbnPZbd9I8C6b9+S05dGRVH1XnrhvtHqpLqK8NX8tVz4xg5LCPH579gi+/5WBbNxRzead1dz99uLodRUAPzhqIE9NWxF3W29fewL77dHwM/vrlDL++IZ3hefpI/qydVctt597CG/MW82M5ZuYOK/5Rrzg+5+8aB2X/mN6cm8+xrlHDODDsvX06VLMyz89Pjp/3dZKRv3+nejj535yDIvXbWu035qz5PdnNuha+dz0lfyf60k2bM8uvPLT4xt85q1x+l3vNVvdceOZB0Z/S7d+6yAuOKq+5LlxRzUlhXkNOkJs2VnD5EXr6FxcwNC+nblj4iJeaWFb0oVHD+SUA/ty/H69KcjPY/DYV+Oud/KwPXjgwiMpKshj/fYqpi7ZwH83cQHoC1cdw2tz1lC+aWej78o3D92Llz/7kkW/Gx2tPXj5sy/56dMzefma4xt0vfbdeOaB/PiEfQCvmnBAj46s21bJX6cs4Z0FaxtcDV5SmMd3j9ybm84e0eousyIyQ1VHNr9mnOemIREcA9ykqqe7xzcAqOof4q3f2kTw5eZdHBtTLdDUQW3x2m2s3LSz0dAOreV/KQCev/IYDh/YA1UlTyTuWXYy6iLKvr98rdH8hbeMjturJ161yKTrTmzUz39HVS1XPfkp733esDj91wuO4Mw4108kS1UZ+8Icni1dGR324Is/nNmoHv/aZ2fx75mrABg9Yk/eiNNN81+Xj+KrQ/swvnQlv3h+doNlfznvMMYc1rgb64dl67kgid4diXxw/dcb9YqaXb6Zs+/7MOFzfnv2CMZNaFx37LvihH345ZkHNph3/fOzebZ0ZcLnTLruRKrrIvx18pJoYvz1WcOjN6Lp3bmY0l+d0uA5qkplTaRB91wR+GzcaazdUklNndK3azEbdlSzV/cOCN7Fllt31bBpZw2De3eM9sBSYPLCdUldNb/41jNYuLrhNSj5ecLjl42KfhZXfW1fZizfxMCeHVt03cv+fTs3qo4J6t+9Awf268rbgV46fzz3kGhCBOjRsZAT9u/DS7NaPxTMOYftxfaqWt5esA6AW8aM4Ncv1X/mC28Zzc2vzE940tKUK0/ct0Fppl+3Ej664eRWxRn2RPAdYLSq/sg9/iFwlKpeE2/91iaCHVW1HH/7pGjx9Jh9evH0FUe3PvBWKFu3jd6di5usS2+p2roI+7nrIR644AhOHd437pleJKL84fUFTFlUweJ13o/nhauObbJK54v1O6J1+f17dODJHx3V4MKn3aGqqMavatpeVctBTRSH7/7+YZxzeP2BXlW5/Y1F7N+3M3t0KeH4oY17Wfnun1zGHRMbj/uyf9/ODOzZkflfbmVYv67819f2pXT5Jm57fSG3nHMQF4wamDBhb9lZwy9fnMOrs1fTsSifCdccx8CenSjI85L8ox98QceifM49cgCL1jQcDC9eyQW872tslcDpI/ry46/uw8jBPRutH4ko+7iTgg/HntSg/SXo7Ps+YHZ56q4yvmXMCE4bsSczV2xi5srNPPSu11nhhP37MO6bw9nXnWQEk3tLHTKgWzTmW845iJOH7cGOqlr226MzUxZVUFyQx9C+XTjjL+81uN4l1jcO7sf9rurz7flrGTdh3m51/+1SUsDTPz6ag/p3Y+aKTXzrr1MbrfOL0w/g6q/vFz0RG96vK//+r2MZMW5iwutgfBcdM4jrRw/jnPs/jP5mTxvel4cvatWxvP0nAhG5ArgCYODAgUcuX950r5Km1EWU/DxBVeOOm98etfS91EWUPCH0739JxXbKN+3iky82cNlxQ+jhEmhrS1C+DdurWLlpF0X5eezds0O0UTWeluzbZNetiyhzVm3hoL26Nlk9s25rJZ8s28ix+/amZ6fmTx5UlWUbdjKkd6cm11uzpZId1bVMWVRBXSTCwjXbGNyrE8UFeSxas41h/bzEtGFHdbRnUpeSQnoEGrU7FxdywJ5dOGJg96Tes6ryubtgc+aKzfTpUsxRQ3qybMNO3pi7hs/XbuN/Tz+AriUF5OcJnYoLWL5hJz07FTX7fuJtqy6iPDN9JT06FnHmwXtGlwVjra6NMHHeGo7epxcfL93AyQfuQYfCfJ6ZvpKORfmMOax/9DOtrKljacUOenUuoro2woAeHRq9753Vtbw1fy1zyrdQXRfhJyfu2yAhv7+4ggP6dmEPd/Hg4rXbqNhWxeJ12zl8YHe2VdayrbKGk4b15aVZqzh2v97R56sqC9dsY2DPjtEbVLVU2BNBWqqGjDEml+1OIkhHr6HpwFARGSIiRcB5wIQ0bNcYY0wSWlcGaQFVrRWRa4CJQD7wqKombl0zxhiTVm1eNdRSIlIBtL6RAHoD8Tuph0t7iLM9xAgWZ6pZnKmVrjgHqWricWCaELpEsLtEpLS19WTp1B7ibA8xgsWZahZnarWHOLNyiAljjDHJs0RgjDE5LhsTwcOZDiBJ7SHO9hAjWJypZnGmVujjzLo2AmOMMS2TjSUCY4wxLWCJwBhjclzWJIJ03/OgmVj2FpHJIjJfROaJyP+4+T1F5C0RWez+93DzRUTucbHPFpEjmt5CSmPNF5GZIvKKezxERKa5WJ51V4MjIsXucZlbPjiNMXYXkedFZKGILBCRY0K6L3/uPu+5IvK0iJSEYX+KyKMisk5E5gbmtXj/icjFbv3FInJxmuK8w33us0XkPyLSPbDsBhfnIhE5PTC/TY8F8eIMLLtORFREervHGdufLeKNEtm+//CuWF4C7AMUAZ8BwzMYTz/gCDfdBe9+DMOBPwJj3fyxwO1u+kzgdUCAo4FpaYz1WuAp4BX3+DngPDf9IHCVm/4v4EE3fR7wbBpjfAz4kZsuArqHbV8C/YEvgA6B/XhJGPYncAJwBDA3MK9F+w/oCSx1/3u46R5piPM0oMBN3x6Ic7j7nRcDQ9zvPz8dx4J4cbr5e+ONoLAc6J3p/dmi95SpDaf4gzkGmBh4fANwQ6bjCsTzEt6NeRYB/dy8fsAiN/0Q3s16/PWj67VxXAOAd4CTgFfcl3V94IcX3a/uC36Mmy5w60kaYuzmDrASMz9s+7I/sNL9sAvc/jw9LPsTGBxzgG3R/gPOBx4KzG+wXlvFGbPsW8CTbrrBb9zfn+k6FsSLE3geOBRYRn0iyOj+TPYvW6qG/B+hr9zNyzhX5D8cmAb0VVX/dkxrAP+uOJmK/27g/wD/Vkm9gM2q6t9ENRhHNEa3fItbv60NASqAf7gqrL+LSCdCti9VdRXwJ2AFsBpv/8wgfPvT19L9F4bf2GV4Z9c0EU9G4hSRMcAqVY29h2eo4kwkWxJBKIlIZ+AF4GequjW4TL3TgIz13RWRs4B1qhr/JrnhUYBXDH9AVQ8HduBVZURlel8CuDr2MXiJay+gEzA6kzElKwz7rzkiciNQCzyZ6VhiiUhH4JfAbzIdS2tlSyJYhVc/5xvg5mWMiBTiJYEnVfXfbvZaEennlvcD1rn5mYj/OOBsEVkGPINXPfQXoLuI+KPSBuOIxuiWdwMa38U99cqBclX170H5PF5iCNO+BDgF+EJVK1S1Bvg33j4O2/70tXT/Zew3JiKXAGcBF7ikRRPxZCLOffFOAD5zv6cBwKcismfI4kwoWxJBqO55ICICPAIsUNU7A4smAH7vgIvx2g78+Re5HgZHA1sCxfY2oao3qOoAVR2Mt78mqeoFwGTgOwli9GP/jlu/zc8iVXUNsFJEDnCzTgbmE6J96awAjhaRju7z9+MM1f4MaOn+mwicJiI9XOnnNDevTYnIaLzqy7NVdWdM/Oe53ldDgKHAJ2TgWKCqc1R1D1Ud7H5P5XidRdYQsv2ZUKYaJ1L9h9c6/zlej4EbMxzL8XhF7dnALPd3Jl4d8DvAYuBtoKdbX4D7XexzgJFpjvdr1Pca2gfvB1UGjAeK3fwS97jMLd8njfEdBpS6/fkiXi+L0O1L4LfAQmAu8C+8Hi0Z35/A03jtFjV4B6nLW7P/8Oroy9zfpWmKswyvLt3/HT0YWP9GF+ci4IzA/DY9FsSLM2b5MuobizO2P1vyZ0NMGGNMjmu2aqipiyfc8vZxwYQxxpi4kmkj+CdN9344A69+bihwBfAAeFcuAuOAo4BRwDj/6kVjjDHh0WwiUNX3gI1NrDIGeFw9H+P1kuiHdzHNW6q6UVU3AW/RTrrTGWNMLknFzet3+4IJEbkCrzRBp06djhw2bFgKwjLGmNwxY8aM9drKexanIhHsNlV9GHfzhpEjR2ppaWmGIzLGmPZFRJa39rmpuI6gXVwwYYwxJr5UJIL2ccGEMcaYuJqtGhKRp/EuOOotIuV4PYEKAVT1QeA1vAs4yoCdwKVu2UYRuQXvSj+Am1W1qUZnY4wxGdBsIlDV85tZrsDVCZY9CjzautCMMSY31dTUUF5eTmVlZaNlJSUlDBgwgMLCwpRtLxSNxcYYY+qVl5fTpUsXBg8ejDd0lUdV2bBhA+Xl5QwZMiRl28uWQeeMMSZrVFZW0qtXrwZJAEBE6NWrV9ySwu6wRGCMMSEUmwSam787LBEYY0yOs0RgjDE5zhKBMcaEUKJbBLTFrQMsERhjTMiUlJSwYcOGRgd9v9dQSUlJSrdn3UeNMSZkBgwYQHl5ORUVFY2W+dcRpJIlAmOMCZnCwsKUXifQHKsaMsaYHGeJwBhjcpwlAmOMyXGWCIwxJsdZIjDGmBxnicAYY3JcUolAREaLyCIRKRORsXGW3yUis9zf5yKyObCsLrBsQiqDN8YYs/uSuUNZPnA/cCpQDkwXkQmqOt9fR1V/Hlj/p8DhgZfYpaqHpS5kY4wxqZRMiWAUUKaqS1W1GngGGNPE+ucDT6ciOGOMMW0vmUTQH1gZeFzu5jUiIoOAIcCkwOwSESkVkY9F5JxWR2qMMaZNpHqIifOA51W1LjBvkKquEpF9gEkiMkdVlwSfJCJXAFcADBw4MMUhGWOMaUoyJYJVwN6BxwPcvHjOI6ZaSFVXuf9LgSk0bD/w13lYVUeq6sg+ffokEZIxxphUSSYRTAeGisgQESnCO9g36v0jIsOAHsBHgXk9RKTYTfcGjgPmxz7XGGNM5jRbNaSqtSJyDTARyAceVdV5InIzUKqqflI4D3hGGw6gfSDwkIhE8JLObcHeRsYYYzJP2uJuN7tj5MiRWlpamukwjDGmXRGRGao6sjXPtSuLjTEmx1kiMMaYHGeJwBhjcpwlAmOMyXGWCIwxJsdZIjDGmBxnicAYY3KcJQJjjMlxlgiMMSbHWSIwxpgcZ4nAGGNynCUCY4zJcZYIjDEmx1kiMMaYHGeJwBhjcpwlAmOMyXFJJQIRGS0ii0SkTETGxll+iYhUiMgs9/ejwLKLRWSx+7s4lcEbY4zZfc3eqlJE8oH7gVOBcmC6iEyIc8vJZ1X1mpjn9gTGASMBBWa4525KSfTGGGN2WzIlglFAmaouVdVq4BlgTJKvfzrwlqpudAf/t4DRrQvVGGNMW0gmEfQHVgYel7t5sc4Vkdki8ryI7N2S54rIFSJSKiKlFRUVSYZujDEmFVLVWPwyMFhVD8E763+sJU9W1YdVdaSqjuzTp0+KQjLGGJOMZBLBKmDvwOMBbl6Uqm5Q1Sr38O/Akck+1xhjTGYlkwimA0NFZIiIFAHnAROCK4hIv8DDs4EFbnoicJqI9BCRHsBpbp4xxpiQaLbXkKrWisg1eAfwfOBRVZ0nIjcDpao6AfhvETkbqAU2Ape4524UkVvwkgnAzaq6sQ3ehzHGmFYSVc10DA2MHDlSS0tLMx2GMca0KyIyQ1VHtua5dmWxMcbkOEsExhiT4ywRGGNMjrNEYIwxOc4SgTHG5DhLBMYYk+MsERhjTI6zRGCMMTnOEoExxuQ4SwTGGJPjLBEYY0yOs0RgjDE5zhKBMcbkOEsExhiT4ywRGGNMjrNEYIwxOS6pRCAio0VkkYiUicjYOMuvFZH5IjJbRN4RkUGBZXUiMsv9TYh9rjHGmMxq9laVIpIP3A+cCpQD00VkgqrOD6w2ExipqjtF5Crgj8D33bJdqnpYiuM2xhiTIsmUCEYBZaq6VFWrgWeAMcEVVHWyqu50Dz8GBqQ2TGOMMW0lmUTQH1gZeFzu5iVyOfB64HGJiJSKyMcick68J4jIFW6d0oqKiiRCMsYYkyrNVg21hIhcCIwETgzMHqSqq0RkH2CSiMxR1SXB56nqw8DD4N28PpUxGWOMaVoyJYJVwN6BxwPcvAZE5BTgRuBsVa3y56vqKvd/KTAFOHw34jXGGJNiySSC6cBQERkiIkXAeUCD3j8icjjwEF4SWBeY30NEit10b+A4INjIbIwxJsOarRpS1VoRuQaYCOQDj6rqPBG5GShV1QnAHUBnYLyIAKxQ1bOBA4GHRCSCl3Rui+ltZIwxJsNENVxV8iNHjtTS0tJMh2GMMe2KiMxQ1ZGtea5dWWyMMTnOEoExxuQ4SwTGGJPjLBEYY0yOs0RgjDE5zhKBMcbkOEsExhiT4ywRGGNMjrNEYIwxOc4SgTHG5DhLBMYYk+MsERhjTI6zRGCMMTnOEoExxuQ4SwTGGJPjkkoEIjJaRBaJSJmIjI2zvFhEnnXLp4nI4MCyG9z8RSJyeupCN8YYkwrNJgIRyQfuB84AhgPni8jwmNUuBzap6n7AXcDt7rnD8W5tOQIYDfzVvZ4xxpiQSKZEMAooU9WlqloNPAOMiVlnDPCYm34eOFm8e1aOAZ5R1SpV/QIoc69njDEmJJJJBP2BlYHH5W5e3HVUtRbYAvRK8rnGGGMyqNmb16eDiFwBXOEeVonI3EzGEyK9gfWZDiIkbF/Us31Rz/ZFvQNa+8RkEsEqYO/A4wFuXrx1ykWkAOgGbEjyuajqw8DDACJS2tobMGcb2xf1bF/Us31Rz/ZFPREpbe1zk6kamg4MFZEhIlKE1/g7IWadCcDFbvo7wCRVVTf/PNeraAgwFPiktcEaY4xJvWZLBKpaKyLXABOBfOBRVZ0nIjcDpao6AXgE+JeIlAEb8ZIFbr3ngPlALXC1qta10XsxxhjTCkm1Eajqa8BrMfN+E5iuBL6b4Lm3Are2IKaHW7ButrN9Uc/2RT3bF/VsX9Rr9b4QrwbHGGNMrrIhJowxJsdlLBHszrAV2SaJfXGtiMwXkdki8o6IDMpEnOnQ3L4IrHeuiKiIZG2PkWT2hYh8z3035onIU+mOMV2S+I0MFJHJIjLT/U7OzEScbU1EHhWRdYm62IvnHrefZovIEUm9sKqm/Q+v0XkJsA9QBHwGDI9Z57+AB930ecCzmYg1JPvi60BHN31VLu8Lt14X4D3gY2BkpuPO4PdiKDAT6OEe75HpuDO4Lx4GrnLTw4FlmY67jfbFCcARwNwEy88EXgcEOBqYlszrZqpEsDvDVmSbZveFqk5W1Z3u4cd412Nko2S+FwC34I1nVZnO4NIsmX3xY+B+Vd0EoKrr0hxjuiSzLxTo6qa7AV+mMb60UdX38HpmJjIGeFw9HwPdRaRfc6+bqUSwO8NWZJuWDsNxOV7Gz0bN7gtX1N1bVV9NZ2AZkMz3Yn9gfxH5UEQ+FpHRaYsuvZLZFzcBF4pIOV4Px5+mJ7TQadWwPqEYYsIkR0QuBEYCJ2Y6lkwQkTzgTuCSDIcSFgV41UNfwyslviciB6vq5oxGlRnnA/9U1T+LyDF41zUdpKqRTAfWHmSqRNCSYSuIGbYi2yQ1DIeInALcCJytqlVpii3dmtsXXYCDgCkisgyvDnRCljYYJ/O9KAcmqGqNeqP7fo6XGLJNMvvicuA5AFX9CCjBG4co1yR1PImVqUSwO8NWZJtm94WIHA48hJcEsrUeGJrZF6q6RVV7q+pgVR2M115ytqq2eoyVEEvmN/IiXmkAEemNV1W0NJ1Bpkky+2IFcDKAiByIlwgq0hplOEwALnK9h44Gtqjq6uaelJGqId2NYSuyTZL74g6gMzDetZevUNWzMxZ0G0lyX+SEJPfFROA0EZkP1AG/UNWsKzUnuS+uA/4mIj/Hazi+JBtPHEXkabzk39u1h4wDCgFU9UG89pEz8e79shO4NKnXzcJ9ZYwxpgXsymJjjMlxlgiMMSbHWSIwxpgcZ4nAGGNynCUCY4zJcZYIjDEmx1kiMMaYHGeJwBhjctz/A9wIQ/uGSkZFAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparison : MAE : 8.076923076923077\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "benchmark = pd.read_csv('submission_vibodha_24.44.csv')\n",
    "submission = pd.read_csv('submission_new_nn.csv')\n",
    "\n",
    "train = pd.read_csv(train_label_filename)\n",
    "\n",
    "figs, axes = plt.subplots(nrows=2, ncols=1)\n",
    "\n",
    "# benchmark.total_cases.plot(ax=axes[0], label=\"Predictions\")\n",
    "# submission.total_cases.plot(ax=axes[0], label=\"Actual\")\n",
    "train.total_cases.plot(ax=axes[0], label=\"Train\")\n",
    "    \n",
    "plt.suptitle(\"Dengue Predicted Cases vs. Actual Cases\")\n",
    "plt.legend()\n",
    "\n",
    "plt.show()\n",
    "\n",
    "print(\"Comparison : MAE : \" + str(mean_absolute_error(benchmark.total_cases, submission.total_cases)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
